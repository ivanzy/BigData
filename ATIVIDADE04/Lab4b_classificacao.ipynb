{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "",
  "signature": "sha256:44db67fc3f9b109e66cee0cfc3a023451478d6d7b3c19217c01c58660ff00f91"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![CMCC](http://cmcc.ufabc.edu.br/images/logo_site.jpg)\n",
      "# **Modelos de Classifica\u00e7\u00e3o**\n",
      "\n",
      "#### Este laborat\u00f3rio ir\u00e1 cobrir os passos para tratar a base de dados de taxa de cliques (click-through rate - CTR) e criar um modelo de classifica\u00e7\u00e3o para tentar determinar se um usu\u00e1rio ir\u00e1 ou n\u00e3o clicar em um banner.\n",
      "\n",
      "#### Para isso utilizaremos a base de dados [Criteo Labs](http://labs.criteo.com/) que foi utilizado em uma competi\u00e7\u00e3o do [Kaggle](https://www.kaggle.com/c/criteo-display-ad-challenge).\n",
      "\n",
      "#### ** Nesse notebook: **\n",
      "+  ####*Parte 1:* Utiliza\u00e7\u00e3o do one-hot-encoding (OHE) para transformar atributos categ\u00f3ricos em num\u00e9ricos\n",
      "+  ####*Parte 2:* Construindo um dicion\u00e1rio OHE\n",
      "+  ####*Parte 3:* Gera\u00e7\u00e3o de atributos OHE na base de dados CTR\n",
      " + #### *Visualiza\u00e7\u00e3o 1:* Frequ\u00eancia de atributos\n",
      "+  ####*Parte 4:* Predi\u00e7\u00e3o de CTR e avalia\u00e7\u00e3o da perda logar\u00edtimica (logloss)\n",
      " + #### *Visualiza\u00e7\u00e3o 2:* Curva ROC\n",
      "+  ####*Parte 5:* Reduzindo a dimens\u00e3o dos atributos atrav\u00e9s de hashing (feature hashing)\n",
      " \n",
      "#### Refer\u00eancias de m\u00e9todos: [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)e [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Part 1: Utiliza\u00e7\u00e3o do one-hot-encoding (OHE) para transformar atributos categ\u00f3ricos em num\u00e9ricos **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (1a) One-hot-encoding **\n",
      "\n",
      "#### Para um melhor entendimento do processo da codifica\u00e7\u00e3o OHE vamos trabalhar com uma base de dados pequena e sem r\u00f3tulos. Cada objeto dessa base pode conter tr\u00eas atributos, o primeiro indicando o animal, o segundo a cor e o terceiro qual animal que ele come.\n",
      "\n",
      "#### No esquema OHE, queremos representar cada tupla `(IDatributo, categoria)` atrav\u00e9s de um atributo bin\u00e1rio. N\u00f3s podemos fazer isso no Python criando um dicion\u00e1rio que mapeia cada poss\u00edvel tupla em um inteiro que corresponde a sua posi\u00e7\u00e3o no vetor de atributos bin\u00e1rio.\n",
      "\n",
      "#### Para iniciar crie um dicion\u00e1rio correspondente aos atributos categ\u00f3ricos da base constru\u00edda logo abaixo. Fa\u00e7a isso manualmente."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Data for manual OHE\n",
      "# Note: the first data point does not include any value for the optional third feature\n",
      "sampleOne = [(0, 'mouse'), (1, 'black')]\n",
      "sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
      "sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]\n",
      "sampleDataRDD = sc.parallelize([sampleOne, sampleTwo, sampleThree])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "sampleOHEDictManual = sampleDataRDD.flatMap(lambda x: x).zipWithIndex().collectAsMap()\n",
      "sampleOHEDictManual = {(0, 'bear'):0,(0, 'cat'):1,(0, 'mouse'):2,(1, 'black'):3,\n",
      "                       (1, 'tabby'):4, (2, 'mouse'):5, (2, 'salmon'):6}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST One-hot-encoding (1a)\n",
      "from test_helper import Test\n",
      "\n",
      "Test.assertEqualsHashed(sampleOHEDictManual[(0,'bear')],\n",
      "                        'b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
      "                        \"incorrect value for sampleOHEDictManual[(0,'bear')]\")\n",
      "Test.assertEqualsHashed(sampleOHEDictManual[(0,'cat')],\n",
      "                        '356a192b7913b04c54574d18c28d46e6395428ab',\n",
      "                        \"incorrect value for sampleOHEDictManual[(0,'cat')]\")\n",
      "Test.assertEqualsHashed(sampleOHEDictManual[(0,'mouse')],\n",
      "                        'da4b9237bacccdf19c0760cab7aec4a8359010b0',\n",
      "                        \"incorrect value for sampleOHEDictManual[(0,'mouse')]\")\n",
      "Test.assertEqualsHashed(sampleOHEDictManual[(1,'black')],\n",
      "                        '77de68daecd823babbb58edb1c8e14d7106e83bb',\n",
      "                        \"incorrect value for sampleOHEDictManual[(1,'black')]\")\n",
      "Test.assertEqualsHashed(sampleOHEDictManual[(1,'tabby')],\n",
      "                        '1b6453892473a467d07372d45eb05abc2031647a',\n",
      "                        \"incorrect value for sampleOHEDictManual[(1,'tabby')]\")\n",
      "Test.assertEqualsHashed(sampleOHEDictManual[(2,'mouse')],\n",
      "                        'ac3478d69a3c81fa62e60f5c3696165a4e5e6ac4',\n",
      "                        \"incorrect value for sampleOHEDictManual[(2,'mouse')]\")\n",
      "Test.assertEqualsHashed(sampleOHEDictManual[(2,'salmon')],\n",
      "                        'c1dfd96eea8cc2b62785275bca38ac261256e278',\n",
      "                        \"incorrect value for sampleOHEDictManual[(2,'salmon')]\")\n",
      "Test.assertEquals(len(sampleOHEDictManual.keys()), 7,\n",
      "                  'incorrect number of keys in sampleOHEDictManual')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (1b) Vetores Esparsos **\n",
      "\n",
      "#### Pontos de dados categ\u00f3ricos geralmente apresentam um pequeno conjunto de OHE n\u00e3o-nulos relativo ao total de poss\u00edveis atributos. Tirando proveito dessa propriedade podemos representar nossos dados como vetores esparsos, economizando espa\u00e7o de armazenamento e c\u00e1lculos computacionais.\n",
      "\n",
      "#### No pr\u00f3ximo exerc\u00edcio transforme os vetores com nome precedidos de `Dense` para vetores esparsos. Utilize a classe [SparseVector](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.SparseVector) para represent\u00e1-los e verifique que ambas as representa\u00e7\u00f5es retornam o mesmo resultado nos c\u00e1lculos dos produtos interno.\n",
      "\n",
      "#### Use `SparseVector(tamanho, *args)` para criar um novo vetor esparso onde `tamanho` \u00e9 o tamanho do vetor e `args` pode ser um dicion\u00e1rio, uma lista de tuplas (\u00edndice, valor) ou duas arrays separadas de \u00edndices e valores ordenados por \u00edndice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from pyspark.mllib.linalg import SparseVector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named pyspark.mllib.linalg",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-3b1b6518a4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mImportError\u001b[0m: No module named pyspark.mllib.linalg"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "aDense = np.array([0., 3., 0., 4.])\n",
      "aSparse = SparseVector(4,[0,1,2,3],aDense)\n",
      "\n",
      "bDense = np.array([0., 0., 0., 1.])\n",
      "bSparse = SparseVector(4,[0,1,2,3],bDense)\n",
      "\n",
      "w = np.array([0.4, 3.1, -1.4, -.5])\n",
      "print aDense.dot(w)\n",
      "print aSparse.dot(w)\n",
      "print bDense.dot(w)\n",
      "print bSparse.dot(w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'SparseVector' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-d32efdc231fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# EXERCICIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maDense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maSparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparseVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maDense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbDense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'SparseVector' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Sparse Vectors (1b)\n",
      "Test.assertTrue(isinstance(aSparse, SparseVector), 'aSparse needs to be an instance of SparseVector')\n",
      "Test.assertTrue(isinstance(bSparse, SparseVector), 'aSparse needs to be an instance of SparseVector')\n",
      "Test.assertTrue(aDense.dot(w) == aSparse.dot(w),\n",
      "                'dot product of aDense and w should equal dot product of aSparse and w')\n",
      "Test.assertTrue(bDense.dot(w) == bSparse.dot(w),\n",
      "                'dot product of bDense and w should equal dot product of bSparse and w')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'Test' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-2a7a9caade4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TEST Sparse Vectors (1b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertTrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maSparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aSparse needs to be an instance of SparseVector'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertTrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbSparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aSparse needs to be an instance of SparseVector'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m Test.assertTrue(aDense.dot(w) == aSparse.dot(w),\n\u001b[1;32m      5\u001b[0m                 'dot product of aDense and w should equal dot product of aSparse and w')\n",
        "\u001b[0;31mNameError\u001b[0m: name 'Test' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(1c) Atributos OHE como vetores esparsos **\n",
      "\n",
      "#### Agora vamos representar nossos atributos OHE como vetores esparsos. Utilizando o dicion\u00e1rio `sampleOHEDictManual`, crie um vetor esparso para cada amostra de nossa base de dados. Todo atributo que ocorre em uma amostra deve ter valor 1.0. Por exemplo, um vetor para um ponto com os atributos 2 e 4 devem ser `[0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reminder of the sample features\n",
      "# sampleOne = [(0, 'mouse'), (1, 'black')]\n",
      "# sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
      "# sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "sampleOneOHEFeatManual = SparseVector(7,[2,3],[1.0,1.0])\n",
      "sampleTwoOHEFeatManual = SparseVector(7, [1,4,5],  [1.0,1.0,1.0])\n",
      "sampleThreeOHEFeatManual = SparseVector(7,[0,3,6],[1.0,1.0,1.0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST OHE Features as sparse vectors (1c)\n",
      "Test.assertTrue(isinstance(sampleOneOHEFeatManual, SparseVector),\n",
      "                'sampleOneOHEFeatManual needs to be a SparseVector')\n",
      "Test.assertTrue(isinstance(sampleTwoOHEFeatManual, SparseVector),\n",
      "                'sampleTwoOHEFeatManual needs to be a SparseVector')\n",
      "Test.assertTrue(isinstance(sampleThreeOHEFeatManual, SparseVector),\n",
      "                'sampleThreeOHEFeatManual needs to be a SparseVector')\n",
      "Test.assertEqualsHashed(sampleOneOHEFeatManual,\n",
      "                        'ecc00223d141b7bd0913d52377cee2cf5783abd6',\n",
      "                        'incorrect value for sampleOneOHEFeatManual')\n",
      "Test.assertEqualsHashed(sampleTwoOHEFeatManual,\n",
      "                        '26b023f4109e3b8ab32241938e2e9b9e9d62720a',\n",
      "                        'incorrect value for sampleTwoOHEFeatManual')\n",
      "Test.assertEqualsHashed(sampleThreeOHEFeatManual,\n",
      "                        'c04134fd603ae115395b29dcabe9d0c66fbdc8a7',\n",
      "                        'incorrect value for sampleThreeOHEFeatManual')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(1d) Fun\u00e7\u00e3o de codifica\u00e7\u00e3o OHE **\n",
      "\n",
      "#### Vamos criar uma fun\u00e7\u00e3o que gera um vetor esparso codificado por um dicion\u00e1rio de OHE. Ele deve fazer o procedimento similar ao exerc\u00edcio anterior."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n",
      "        one = [1.0]*len(rawFeats)\n",
      "        vec = []\n",
      "        for x in range(0,len(rawFeats)):\n",
      "            vec.append(OHEDict[rawFeats[x]])\n",
      "        vec.sort()\n",
      "        return SparseVector(numOHEFeats,vec,one)\n",
      "\n",
      "# Calculate the number of features in sampleOHEDictManual\n",
      "numSampleOHEFeats = len(sampleOHEDictManual)\n",
      "\n",
      "# Run oneHotEnoding on sampleOne\n",
      "sampleOneOHEFeat = oneHotEncoding(sampleOne, sampleOHEDictManual, numSampleOHEFeats)\n",
      "\n",
      "print sampleOneOHEFeat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Define an OHE Function (1d)\n",
      "Test.assertTrue(sampleOneOHEFeat == sampleOneOHEFeatManual,\n",
      "                'sampleOneOHEFeat should equal sampleOneOHEFeatManual')\n",
      "Test.assertEquals(sampleOneOHEFeat, SparseVector(7, [2,3], [1.0,1.0]),\n",
      "                  'incorrect value for sampleOneOHEFeat')\n",
      "Test.assertEquals(oneHotEncoding([(1, 'black'), (0, 'mouse')], sampleOHEDictManual,\n",
      "                                 numSampleOHEFeats), SparseVector(7, [2,3], [1.0,1.0]),\n",
      "                  'incorrect definition for oneHotEncoding')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(1e) Aplicar OHE em uma base de dados **\n",
      "\n",
      "#### Finalmente, use a fun\u00e7\u00e3o da parte (1d) para criar atributos OHE para todos os 3 objetos da base de dados artificial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "sampleOHEData = sampleDataRDD.map(lambda x : oneHotEncoding(x,sampleOHEDictManual,numSampleOHEFeats))\n",
      "print sampleOHEData.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Apply OHE to a dataset (1e)\n",
      "sampleOHEDataValues = sampleOHEData.collect()\n",
      "Test.assertTrue(len(sampleOHEDataValues) == 3, 'sampleOHEData should have three elements')\n",
      "Test.assertEquals(sampleOHEDataValues[0], SparseVector(7, {2: 1.0, 3: 1.0}),\n",
      "                  'incorrect OHE for first sample')\n",
      "Test.assertEquals(sampleOHEDataValues[1], SparseVector(7, {1: 1.0, 4: 1.0, 5: 1.0}),\n",
      "                  'incorrect OHE for second sample')\n",
      "Test.assertEquals(sampleOHEDataValues[2], SparseVector(7, {0: 1.0, 3: 1.0, 6: 1.0}),\n",
      "                  'incorrect OHE for third sample')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Part 2: Construindo um dicion\u00e1rio OHE **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(2a) Tupla RDD de `(IDatributo, categoria)` **\n",
      "\n",
      "#### Crie um RDD de pares distintos de `(IDatributo,  categoria)`. Em nossa base de dados voc\u00ea deve gerar `(0, 'bear')`, `(0, 'cat')`, `(0, 'mouse')`, `(1, 'black')`, `(1, 'tabby')`, `(2, 'mouse')`, `(2, 'salmon')`. Repare que `'black'` aparece duas vezes em nossa base de dados mas contribui apenas para um item do RDD: `(1, 'black')`, por outro lado `'mouse'` aparece duas vezes e contribui para dois itens: `(0, 'mouse')` and `(2, 'mouse')`.  \n",
      "\n",
      "#### Dica: use [flatMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.flatMap) e [distinct](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.distinct)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "sampleDistinctFeats = (sampleDataRDD\n",
      "                       .flatMap(lambda x: x)\n",
      "                       .distinct()\n",
      "                      )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Pair RDD of (featureID, category) (2a)\n",
      "Test.assertEquals(sorted(sampleDistinctFeats.collect()),\n",
      "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
      "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
      "                  'incorrect value for sampleDistinctFeats')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (2b) Dicion\u00e1rio OHE de atributos \u00fanicos **\n",
      "\n",
      "#### Agora, vamos criar um RDD de tuplas para cada `(IDatributo, categoria)` em `sampleDistinctFeats`. A chave da tupla \u00e9 a pr\u00f3pria tupla original, e o valor ser\u00e1 um inteiro variando de 0 at\u00e9 n\u00famero de tuplas - 1. \n",
      "\n",
      "#### Em seguida, converta essa `RDD` em um dicion\u00e1rio, utilizando o comando `collectAsMap`. \n",
      "\n",
      "#### Use o comando  [zipWithIndex](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.zipWithIndex) seguido de [collectAsMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collectAsMap).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "sampleOHEDict = (sampleDistinctFeats\n",
      "                           .zipWithIndex()\n",
      "                           .collectAsMap())\n",
      "print sampleOHEDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST OHE Dictionary from distinct features (2b)\n",
      "Test.assertEquals(sorted(sampleOHEDict.keys()),\n",
      "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
      "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
      "                  'sampleOHEDict has unexpected keys')\n",
      "Test.assertEquals(sorted(sampleOHEDict.values()), range(7), 'sampleOHEDict has unexpected values')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(2c) Cria\u00e7\u00e3o autom\u00e1tica do dicion\u00e1rio OHE **\n",
      "\n",
      "#### Agora use os c\u00f3digos dos exerc\u00edcios anteriores para criar uma fun\u00e7\u00e3o que retorna um dicion\u00e1rio OHE a partir dos atributos categ\u00f3ricos de uma base de dados."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def createOneHotDict(inputData):\n",
      "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
      "\n",
      "    Args:\n",
      "        inputData (RDD of lists of (int, str)): An RDD of observations where each observation is\n",
      "            made up of a list of (featureID, value) tuples.\n",
      "\n",
      "    Returns:\n",
      "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
      "            unique integers.\n",
      "    \"\"\"\n",
      "    return (inputData.flatMap(lambda x: x).distinct().zipWithIndex().collectAsMap())\n",
      "\n",
      "sampleOHEDictAuto = createOneHotDict(sampleDataRDD)\n",
      "print sampleOHEDictAuto"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Automated creation of an OHE dictionary (2c)\n",
      "Test.assertEquals(sorted(sampleOHEDictAuto.keys()),\n",
      "                  [(0, 'bear'), (0, 'cat'), (0, 'mouse'), (1, 'black'),\n",
      "                   (1, 'tabby'), (2, 'mouse'), (2, 'salmon')],\n",
      "                  'sampleOHEDictAuto has unexpected keys')\n",
      "Test.assertEquals(sorted(sampleOHEDictAuto.values()), range(7),\n",
      "                  'sampleOHEDictAuto has unexpected values')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "**Part 3: Parse CTR data and generate OHE features**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Antes de come\u00e7ar essa parte, vamos carregar a base de dados e verificar o formato dela.\n",
      "\n",
      "#### Repare que o primeiro campo \u00e9 o r\u00f3tulo de cada objeto, sendo 0 se o usu\u00e1rio n\u00e3o clicou no banner e 1 caso tenha clicado. O restante dos atributos ou s\u00e3o num\u00e9ricos ou s\u00e3o strings representando categorias an\u00f4nimas. Vamos tratar todos os atributos como categ\u00f3ricos."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os.path\n",
      "baseDir = os.path.join('Data')\n",
      "inputPath = os.path.join('Aula04', 'dac_sample.txt')\n",
      "fileName = os.path.join(baseDir, inputPath)\n",
      "\n",
      "if os.path.isfile(fileName):\n",
      "    rawData = (sc\n",
      "               .textFile(fileName, 2)\n",
      "               .map(lambda x: x.replace('\\t', ',')))  # work with either ',' or '\\t' separated data\n",
      "    print rawData.take(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(3a) Carregando e dividindo os dados **\n",
      "\n",
      "#### Da mesma forma que no notebook anterior, vamos dividir os dados entre treinamento, valida\u00e7\u00e3o e teste. Use o m\u00e9todo [randomSplit](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) com os pesos (weights) e semente aleat\u00f3ria (seed) especificados para criar os conjuntos, ent\u00e3o fa\u00e7a o [cache](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.cache) de cada RDD, pois utilizaremos cada uma delas com frequ\u00eancia durante esse exerc\u00edcio."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "weights = [.8, .1, .1]\n",
      "seed = 42\n",
      "# Use randomSplit with weights and seed\n",
      "rawTrainData, rawValidationData, rawTestData = rawData.randomSplit(weights, seed)\n",
      "# Cache the data\n",
      "rawTrainData.cache()\n",
      "rawValidationData.cache()\n",
      "rawTestData.cache()\n",
      "\n",
      "nTrain = rawTrainData.count()\n",
      "nVal = rawValidationData.count()\n",
      "nTest = rawTestData.count()\n",
      "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
      "print rawData.take(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Loading and splitting the data (3a)\n",
      "Test.assertTrue(all([rawTrainData.is_cached, rawValidationData.is_cached, rawTestData.is_cached]),\n",
      "                'you must cache the split data')\n",
      "Test.assertEquals(nTrain, 79911, 'incorrect value for nTrain')\n",
      "Test.assertEquals(nVal, 10075, 'incorrect value for nVal')\n",
      "Test.assertEquals(nTest, 10014, 'incorrect value for nTest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "#### ** (3b) Extra\u00e7\u00e3o de atributos **\n",
      "\n",
      "#### Como pr\u00f3ximo passo, crie uma fun\u00e7\u00e3o para ser aplicada em cada objeto do RDD para gerar uma RDD de tuplas (IDatributo, categoria). Ignore o primeiro campo, que \u00e9 o r\u00f3tulo e gere uma lista de tuplas para os atributos seguintes. Utilize o comando [enumerate](https://docs.python.org/2/library/functions.html#enumerate) para criar essas tuplas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def parsePoint(point):\n",
      "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
      "\n",
      "    Note:\n",
      "        featureIDs should start at 0 and increase to the number of features - 1.\n",
      "\n",
      "    Args:\n",
      "        point (str): A comma separated string where the first value is the label and the rest\n",
      "            are features.\n",
      "\n",
      "    Returns:\n",
      "        list: A list of (featureID, value) tuples.\n",
      "    \"\"\"\n",
      "    point = point.split(\",\")\n",
      "    del point[0]\n",
      "    return list(enumerate(point, start=0))\n",
      "\n",
      "parsedTrainFeat = rawTrainData.map(parsePoint)\n",
      "\n",
      "numCategories = (parsedTrainFeat\n",
      ".flatMap(lambda x: x)\n",
      ".distinct()\n",
      ".map(lambda x: (x[0], 1))\n",
      ".reduceByKey(lambda x, y: x + y)\n",
      ".sortByKey()\n",
      ".collect())\n",
      "\n",
      "print numCategories[2][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Extract features (3b)\n",
      "Test.assertEquals(numCategories[2][1], 855, 'incorrect implementation of parsePoint')\n",
      "Test.assertEquals(numCategories[32][1], 4, 'incorrect implementation of parsePoint')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(3c) Crie o dicion\u00e1rio de OHE dessa base de dados **\n",
      "\n",
      "#### Note que a fun\u00e7\u00e3o parsePoint retorna um objeto em forma de lista `(IDatributo, categoria)`, que \u00e9 o mesmo formato utilizado pela fun\u00e7\u00e3o `createOneHotDict`. Utilize o RDD `parsedTrainFeat` para criar um dicion\u00e1rio OHE."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "ctrOHEDict = parsedTrainFeat.flatMap(lambda x: x).distinct().zipWithIndex().collectAsMap()\n",
      "numCtrOHEFeats = len(ctrOHEDict.keys())\n",
      "print numCtrOHEFeats\n",
      "print ctrOHEDict[(0, '')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Create an OHE dictionary from the dataset (3c)\n",
      "Test.assertEquals(numCtrOHEFeats, 233286, 'incorrect number of features in ctrOHEDict')\n",
      "Test.assertTrue((0, '') in ctrOHEDict, 'incorrect features in ctrOHEDict')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (3d) Aplicando OHE \u00e0 base de dados **\n",
      "\n",
      "#### Agora vamos usar o dicion\u00e1rio OHE para criar um RDD de objetos [LabeledPoint](http://spark.apache.org/docs/1.3.1/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) usando atributos OHE. Complete a fun\u00e7\u00e3o `parseOHEPoint`. Dica: essa fun\u00e7\u00e3o \u00e9 uma extens\u00e3o da fun\u00e7\u00e3o `parsePoint` criada anteriormente e que usa a fun\u00e7\u00e3o `oneHotEncoding`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.regression import LabeledPoint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def parseOHEPoint(point, OHEDict, numOHEFeats):\n",
      "    \"\"\"Obtain the label and feature vector for this raw observation.\n",
      "\n",
      "    Note:\n",
      "        You must use the function `oneHotEncoding` in this implementation or later portions\n",
      "        of this lab may not function as expected.\n",
      "\n",
      "    Args:\n",
      "        point (str): A comma separated string where the first value is the label and the rest\n",
      "            are features.\n",
      "        OHEDict (dict of (int, str) to int): Mapping of (featureID, value) to unique integer.\n",
      "        numOHEFeats (int): The number of unique features in the training dataset.\n",
      "\n",
      "    Returns:\n",
      "        LabeledPoint: Contains the label for the observation and the one-hot-encoding of the\n",
      "            raw features based on the provided OHE dictionary.\n",
      "            \n",
      "    \"\"\"\n",
      "    point = point.split(\",\")\n",
      "    label = point[0]\n",
      "    del point[0]\n",
      "    return LabeledPoint(label,oneHotEncoding(list(enumerate(point, start=0)), OHEDict, numOHEFeats))\n",
      "    \n",
      "    \n",
      "OHETrainData = rawTrainData.map(lambda point: parseOHEPoint(point, ctrOHEDict, numCtrOHEFeats))\n",
      "OHETrainData.cache()\n",
      "print OHETrainData.take(1)\n",
      "\n",
      "# Check that oneHotEncoding function was used in parseOHEPoint\n",
      "backupOneHot = oneHotEncoding\n",
      "oneHotEncoding = None\n",
      "withOneHot = False\n",
      "try: parseOHEPoint(rawTrainData.take(1)[0], ctrOHEDict, numCtrOHEFeats)\n",
      "except TypeError: withOneHot = True\n",
      "oneHotEncoding = backupOneHot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Apply OHE to the dataset (3d)\n",
      "numNZ = sum(parsedTrainFeat.map(lambda x: len(x)).take(5))\n",
      "numNZAlt = sum(OHETrainData.map(lambda lp: len(lp.features.indices)).take(5))\n",
      "Test.assertEquals(numNZ, numNZAlt, 'incorrect implementation of parseOHEPoint')\n",
      "Test.assertTrue(withOneHot, 'oneHotEncoding not present in parseOHEPoint')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **Visualiza\u00e7\u00e3o 1: Frequ\u00eancia dos Atributos **\n",
      "\n",
      "#### Vamos agora visualizar o n\u00famero de vezes que cada um dos 233.286 atributos OHE aparecem na base de treino.  Para isso primeiro contabilizamos quantas vezes cada atributo aparece na base, ent\u00e3o alocamos cada atributo em um balde de histograma. Os baldes tem tamanhos de pot\u00eancia de 2, ent\u00e3o o primeiro balde conta os atributos que aparecem exatamente uma vez ( $ \\scriptsize 2^0 $ ), o segundo atributos que aparecem duas vezes ( $ \\scriptsize 2^1 $ ), o terceiro os atributos que aparecem de 3 a 4 vezes ( $ \\scriptsize 2^2 $ ), o quinto balde \u00e9 para atributos que ocorrem de cinco a oito vezes ( $ \\scriptsize 2^3 $ ) e assim por diante. O gr\u00e1fico de dispers\u00e3o abaixo mostra o logar\u00edtmo do tamanho dos baldes versus o logar\u00edtmo da frequ\u00eancia de atributos que ca\u00edram nesse balde."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bucketFeatByCount(featCount):\n",
      "    \"\"\"Bucket the counts by powers of two.\"\"\"\n",
      "    for i in range(11):\n",
      "        size = 2 ** i\n",
      "        if featCount <= size:\n",
      "            return size\n",
      "    return -1\n",
      "\n",
      "featCounts = (OHETrainData\n",
      "              .flatMap(lambda lp: lp.features.indices)\n",
      "              .map(lambda x: (x, 1))\n",
      "              .reduceByKey(lambda x, y: x + y))\n",
      "featCountsBuckets = (featCounts\n",
      "                     .map(lambda x: (bucketFeatByCount(x[1]), 1))\n",
      "                     .filter(lambda (k, v): k != -1)\n",
      "                     .reduceByKey(lambda x, y: x + y)\n",
      "                     .collect())\n",
      "print featCountsBuckets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "x, y = zip(*featCountsBuckets)\n",
      "x, y = np.log(x), np.log(y)\n",
      "\n",
      "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
      "                gridWidth=1.0):\n",
      "    \"\"\"Template for generating the plot layout.\"\"\"\n",
      "    plt.close()\n",
      "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
      "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
      "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
      "        axis.set_ticks_position('none')\n",
      "        axis.set_ticks(ticks)\n",
      "        axis.label.set_color('#999999')\n",
      "        if hideLabels: axis.set_ticklabels([])\n",
      "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
      "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
      "    return fig, ax\n",
      "\n",
      "# generate layout and plot data\n",
      "fig, ax = preparePlot(np.arange(0, 10, 1), np.arange(4, 14, 2))\n",
      "ax.set_xlabel(r'$\\log_e(bucketSize)$'), ax.set_ylabel(r'$\\log_e(countInBucket)$')\n",
      "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(3e) Atributos n\u00e3o observados **\n",
      "\n",
      "#### Naturalmente precisaremos aplicar esse mesmo procedimento para as outras bases (valida\u00e7\u00e3o e teste), por\u00e9m nessas bases podem existir atributos n\u00e3o observados na base de treino.\n",
      "\n",
      "#### Precisamos adaptar a fun\u00e7\u00e3o `oneHotEncoding` para ignorar os atributos que n\u00e3o existem no dicion\u00e1rio."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n",
      "    vec = []\n",
      "    cont = 0\n",
      "    for x in range(0,len(rawFeats)):\n",
      "        if rawFeats[x] in OHEDict:\n",
      "            vec.append(OHEDict[rawFeats[x]])\n",
      "            cont = cont+1\n",
      "    vec.sort()\n",
      "    one = [1.0]*cont\n",
      "    return SparseVector(numOHEFeats,vec,one)\n",
      "\n",
      "OHEValidationData = rawValidationData.map(lambda point: parseOHEPoint(point, ctrOHEDict, numCtrOHEFeats))\n",
      "OHEValidationData.cache()\n",
      "print OHEValidationData.take(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Handling unseen features (3e)\n",
      "numNZVal = (OHEValidationData\n",
      "            .map(lambda lp: len(lp.features.indices))\n",
      "            .sum())\n",
      "Test.assertEquals(numNZVal, 372080, 'incorrect number of features')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Part 4: Predi\u00e7\u00e3o do CTR e avalia\u00e7\u00e3o da perda-log (logloss) **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4a) Regress\u00e3o Log\u00edstica **\n",
      "\n",
      "#### Um classificador que podemos utilizar nessa base de dados \u00e9 a regress\u00e3o log\u00edstica, que nos d\u00e1 a probabilidade de um evento de clique em banner ocorrer. Vamos utilizar a fun\u00e7\u00e3o  [LogisticRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithSGD) para treinar um modelo usando  `OHETrainData` com a configura\u00e7\u00e3o de par\u00e2metros dada.  `LogisticRegressionWithSGD` retorna um [LogisticRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LogisticRegressionModel).  \n",
      "\n",
      "#### Em seguida, imprima  `LogisticRegressionModel.weights` e `LogisticRegressionModel.intercept` para verificar o modelo gerado. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
      "\n",
      "\n",
      "\n",
      "# fixed hyperparameters\n",
      "numIters = 50\n",
      "stepSize = 10.\n",
      "regParam = 1e-6\n",
      "regType = 'l2'\n",
      "includeIntercept = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "model0 = LogisticRegressionWithSGD.train(OHETrainData, numIters, stepSize, regParam)\n",
      "sortedWeights = sorted(model0.weights)\n",
      "print sortedWeights[:5], model0.intercept"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Logistic regression (4a)\n",
      "Test.assertTrue(np.allclose(model0.intercept,  0.56455084025), 'incorrect value for model0.intercept')\n",
      "Test.assertTrue(np.allclose(sortedWeights[0:5],\n",
      "                [-0.45899236853575609, -0.37973707648623956, -0.36996558266753304,\n",
      "                 -0.36934962879928263, -0.32697945415010637]), 'incorrect value for model0.weights')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4b) Log loss **\n",
      "\n",
      "#### Uma forma de avaliar um classificador bin\u00e1rio \u00e9 atrav\u00e9s do log-loss, definido como: $$  \\begin{align} \\scriptsize \\ell_{log}(p, y) = \\begin{cases} -\\log (p) & \\text{if } y = 1 \\\\\\ -\\log(1-p) & \\text{if } y = 0 \\end{cases} \\end{align} $$ onde $ \\scriptsize p$ \u00e9 uma probabilidade entre 0 e 1 e  $ \\scriptsize y$ \u00e9 o r\u00f3tulo bin\u00e1rio (0 ou 1). Log loss \u00e9 um crit\u00e9rio de avalia\u00e7\u00e3o muito utilizado quando deseja-se predizer eventos raros. Escreva uma fun\u00e7\u00e3o para calcular o log-loss, e avalie algumas entradas de amostra."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "from math import log\n",
      "def computeLogLoss(p, y):\n",
      "    \"\"\"Calculates the value of log loss for a given probabilty and label.\n",
      "\n",
      "    Note:\n",
      "        log(0) is undefined, so when p is 0 we need to add a small value (epsilon) to it\n",
      "        and when p is 1 we need to subtract a small value (epsilon) from it.\n",
      "\n",
      "    Args:\n",
      "        p (float): A probabilty between 0 and 1.\n",
      "        y (int): A label.  Takes on the values 0 and 1.\n",
      "\n",
      "    Returns:\n",
      "        float: The log loss value.\n",
      "    \"\"\"\n",
      "    if p == 0:\n",
      "        p = 0.00000000001\n",
      "    if p==1:\n",
      "        p =1 - 0.00000000001\n",
      "    if y == 1:\n",
      "        return -(log(p))\n",
      "    else :\n",
      "        return -(log(1-p))\n",
      "\n",
      "print computeLogLoss(.5, 1)\n",
      "print computeLogLoss(.5, 0)\n",
      "print computeLogLoss(.99, 1)\n",
      "print computeLogLoss(.99, 0)\n",
      "print computeLogLoss(.01, 1)\n",
      "print computeLogLoss(.01, 0)\n",
      "print computeLogLoss(0, 1)\n",
      "print computeLogLoss(1, 1)\n",
      "print computeLogLoss(1, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Log loss (4b)\n",
      "Test.assertTrue(np.allclose([computeLogLoss(.5, 1), computeLogLoss(.01, 0), computeLogLoss(.01, 1)],\n",
      "                            [0.69314718056, 0.0100503358535, 4.60517018599]),\n",
      "                'computeLogLoss is not correct')\n",
      "Test.assertTrue(np.allclose([computeLogLoss(0, 1), computeLogLoss(1, 1), computeLogLoss(1, 0)],\n",
      "                            [25.3284360229, 1.00000008275e-11, 25.3284360229]), 'computeLogLoss needs to bound p away from 0 and 1 by epsilon')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4c)  Baseline log loss **\n",
      "\n",
      "#### Agora, vamos utilizar a fun\u00e7\u00e3o da Parte (4b) para calcular um baseline da m\u00e9trica de log-loss na nossa base de treino. Uma forma de calcular um baseline \u00e9 predizer sempre a m\u00e9dia dos r\u00f3tulos observados. Primeiro calcule a m\u00e9dia dos r\u00f3tulos da base e, em seguida, calcule o log-loss m\u00e9dio para a base de treino."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "# Note that our dataset has a very high click-through rate by design\n",
      "# In practice click-through rate can be one to two orders of magnitude lower\n",
      "\n",
      "ones = OHETrainData.filter(lambda x: x.label==1.0).count()\n",
      "total = OHETrainData.count()\n",
      "media = ones/total\n",
      "\n",
      "classOneFracTrain =  media\n",
      "print classOneFracTrain\n",
      "t =  OHETrainData.map(lambda x: computeLogLoss(classOneFracTrain, x.label))\n",
      "t = t.map(lambda x: (x,1)).reduce(lambda (x1,y1),(x2,y2): (x1+x2,y1+y2))\n",
      "logLossTrBase = t[0]/t[1]\n",
      "print 'Baseline Train Logloss = {0:.3f}\\n'.format(logLossTrBase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Baseline log loss (4c)\n",
      "Test.assertTrue(np.allclose(classOneFracTrain, 0.22717773523), 'incorrect value for classOneFracTrain')\n",
      "Test.assertTrue(np.allclose(logLossTrBase, 0.535844), 'incorrect value for logLossTrBase')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4d) Probabilidade da Predi\u00e7\u00e3o **\n",
      "\n",
      "#### O modelo gerado na Parte (4a) possui um m\u00e9todo chamado `predict`, por\u00e9m esse m\u00e9todo retorna apenas 0's e 1's. Para calcular a probabilidade de um evento, vamos criar uma fun\u00e7\u00e3o `getP` que recebe como par\u00e2metro o ponto x, o conjunto de pesos `w` e o `intercept`.\n",
      "\n",
      "#### Calcule o modelo de regress\u00e3o linear nesse ponto x e aplique a  [fun\u00e7\u00e3o sigmoidal](http://en.wikipedia.org/wiki/Sigmoid_function) $ \\scriptsize \\sigma(t) = (1+ e^{-t})^{-1} $ para retornar a probabilidade da predi\u00e7\u00e3o do objeto x.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "from math import exp #  exp(-t) = e^-t\n",
      "\n",
      "def getP(x, w, intercept):\n",
      "    rawPrediction = np.dot(w,x) + intercept\n",
      "    rawPrediction = min(rawPrediction, 20)\n",
      "    rawPrediction = max(rawPrediction, -20)\n",
      "    return (1+exp(-rawPrediction))**(-1)\n",
      "\n",
      "trainingPredictions = OHETrainData.map(lambda x: getP(x.features, model0.weights,model0.intercept ))\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Predicted probability (4d)\n",
      "Test.assertTrue(np.allclose(trainingPredictions.sum(), 18135.4834348),\n",
      "                'incorrect value for trainingPredictions')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4e) Avalie o modelo **\n",
      "\n",
      "#### Finalmente, crie uma fun\u00e7\u00e3o `evaluateResults` que calcula o log-loss m\u00e9dio do modelo em uma base de dados. Em seguida, execute essa fun\u00e7\u00e3o na nossa base de treino."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def evaluateResults(model, data):\n",
      "    \"\"\"Calculates the log loss for the data given the model.\n",
      "\n",
      "    Args:\n",
      "        model (LogisticRegressionModel): A trained logistic regression model.\n",
      "        data (RDD of LabeledPoint): Labels and features for each observation.\n",
      "\n",
      "    Returns:\n",
      "        float: Log loss for the data.\n",
      "    \"\"\"\n",
      "    return (data\n",
      "            .<COMPLETAR>\n",
      "            .<COMPLETAR>\n",
      "            .<COMPLETAR>\n",
      "            )\n",
      "\n",
      "logLossTrLR0 = evaluateResults(model0, OHETrainData)\n",
      "print ('OHE Features Train Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
      "       .format(logLossTrBase, logLossTrLR0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Evaluate the model (4e)\n",
      "Test.assertTrue(np.allclose(logLossTrLR0, 0.456903), 'incorrect value for logLossTrLR0')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4f) log-loss da valida\u00e7\u00e3o **\n",
      "\n",
      "#### Agora aplique o modelo na nossa base de valida\u00e7\u00e3o e calcule o log-loss m\u00e9dio, compare com o nosso baseline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "logLossValBase = OHEValidationData.<COMPLETAR>\n",
      "\n",
      "logLossValLR0 = evaluateResults(model0, OHEValidationData)\n",
      "print ('OHE Features Validation Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
      "       .format(logLossValBase, logLossValLR0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Validation log loss (4f)\n",
      "Test.assertTrue(np.allclose(logLossValBase, 0.527603), 'incorrect value for logLossValBase')\n",
      "Test.assertTrue(np.allclose(logLossValLR0, 0.456957), 'incorrect value for logLossValLR0')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **Visualiza\u00e7\u00e3o 2: Curva ROC  **\n",
      "\n",
      "#### A curva ROC nos mostra o custo-benef\u00edcio entre a taxa de falso positivo e a taxa de verdadeiro positivo, conforme diminuimos o limiar de predi\u00e7\u00e3o. Um modelo aleat\u00f3rio \u00e9 representado por uma linha pontilhada. Idealmente nosso modelo deve formar uma curva acima dessa linha."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labelsAndScores = OHEValidationData.map(lambda lp:\n",
      "                                            (lp.label, getP(lp.features, model0.weights, model0.intercept)))\n",
      "labelsAndWeights = labelsAndScores.collect()\n",
      "labelsAndWeights.sort(key=lambda (k, v): v, reverse=True)\n",
      "labelsByWeight = np.array([k for (k, v) in labelsAndWeights])\n",
      "\n",
      "length = labelsByWeight.size\n",
      "truePositives = labelsByWeight.cumsum()\n",
      "numPositive = truePositives[-1]\n",
      "falsePositives = np.arange(1.0, length + 1, 1.) - truePositives\n",
      "\n",
      "truePositiveRate = truePositives / numPositive\n",
      "falsePositiveRate = falsePositives / (length - numPositive)\n",
      "\n",
      "# Generate layout and plot data\n",
      "fig, ax = preparePlot(np.arange(0., 1.1, 0.1), np.arange(0., 1.1, 0.1))\n",
      "ax.set_xlim(-.05, 1.05), ax.set_ylim(-.05, 1.05)\n",
      "ax.set_ylabel('True Positive Rate (Sensitivity)')\n",
      "ax.set_xlabel('False Positive Rate (1 - Specificity)')\n",
      "plt.plot(falsePositiveRate, truePositiveRate, color='#8cbfd0', linestyle='-', linewidth=3.)\n",
      "plt.plot((0., 1.), (0., 1.), linestyle='--', color='#d6ebf2', linewidth=2.)  # Baseline model\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "**Parte 5: Reduzindo a dimens\u00e3o dos atributos via feature hashing**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (5a) Fun\u00e7\u00e3o Hash **\n",
      "\n",
      "#### Nosso modelo OHE consegue criar uma representa\u00e7\u00e3o num\u00e9rica boa o suficiente para ser aplic\u00e1vel em algoritmos de classifica\u00e7\u00e3o que n\u00e3o conseguem tratar dados categ\u00f3ricos. Por\u00e9m, para nossa base de dados isso gerou um n\u00famero enorme de atributos (233 mil) que pode tornar o problema intrat\u00e1vel. Para reduzir o espa\u00e7o de atributos vamos utilizar um truque atrav\u00e9s de fun\u00e7\u00f5es hash chamado de feature hashing.\n",
      "\n",
      "#### Logo abaixo, j\u00e1 est\u00e1 implementada a fun\u00e7\u00e3o de hash que usaremos nessa parte do notebook. Vamos aplic\u00e1-la na nossa base artificial criada na Parte (1a) para termos uma intui\u00e7\u00e3o do que est\u00e1 acontecendo. Execute essa fun\u00e7\u00e3o para valores diferentes de `numBuckets` e observe o resultado."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "import hashlib\n",
      "\n",
      "def hashFunction(numBuckets, rawFeats, printMapping=False):\n",
      "    \"\"\"Calculate a feature dictionary for an observation's features based on hashing.\n",
      "\n",
      "    Note:\n",
      "        Use printMapping=True for debug purposes and to better understand how the hashing works.\n",
      "\n",
      "    Args:\n",
      "        numBuckets (int): Number of buckets to use as features.\n",
      "        rawFeats (list of (int, str)): A list of features for an observation.  Represented as\n",
      "            (featureID, value) tuples.\n",
      "        printMapping (bool, optional): If true, the mappings of featureString to index will be\n",
      "            printed.\n",
      "\n",
      "    Returns:\n",
      "        dict of int to float:  The keys will be integers which represent the buckets that the\n",
      "            features have been hashed to.  The value for a given key will contain the count of the\n",
      "            (featureID, value) tuples that have hashed to that key.\n",
      "    \"\"\"\n",
      "    mapping = {}\n",
      "    for ind, category in rawFeats:\n",
      "        featureString = category + str(ind)\n",
      "        mapping[featureString] = int(int(hashlib.md5(featureString).hexdigest(), 16) % numBuckets)\n",
      "    if(printMapping): print mapping\n",
      "    sparseFeatures = defaultdict(float)\n",
      "    for bucket in mapping.values():\n",
      "        sparseFeatures[bucket] += 1.0\n",
      "    return dict(sparseFeatures)\n",
      "\n",
      "# Reminder of the sample values:\n",
      "# sampleOne = [(0, 'mouse'), (1, 'black')]\n",
      "# sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
      "# sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "# Use four buckets\n",
      "sampOneFourBuckets = <COMPLETAR>\n",
      "sampTwoFourBuckets = <COMPLETAR>\n",
      "sampThreeFourBuckets = <COMPLETAR>\n",
      "\n",
      "# Use one hundred buckets\n",
      "sampOneHundredBuckets = <COMPLETAR>\n",
      "sampTwoHundredBuckets = <COMPLETAR>\n",
      "sampThreeHundredBuckets = <COMPLETAR>\n",
      "\n",
      "print '\\t\\t 4 Buckets \\t\\t\\t 100 Buckets'\n",
      "print 'SampleOne:\\t {0}\\t\\t {1}'.format(sampOneFourBuckets, sampOneHundredBuckets)\n",
      "print 'SampleTwo:\\t {0}\\t\\t {1}'.format(sampTwoFourBuckets, sampTwoHundredBuckets)\n",
      "print 'SampleThree:\\t {0}\\t {1}'.format(sampThreeFourBuckets, sampThreeHundredBuckets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Hash function (5a)\n",
      "Test.assertEquals(sampOneFourBuckets, {2: 1.0, 3: 1.0}, 'incorrect value for sampOneFourBuckets')\n",
      "Test.assertEquals(sampThreeHundredBuckets, {72: 1.0, 5: 1.0, 14: 1.0},\n",
      "                  'incorrect value for sampThreeHundredBuckets')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (5b) Criando hashed features **\n",
      "\n",
      "#### Agora vamos usar essa fun\u00e7\u00e3o hash para criar hashed features para nossa base CTR. Primeiro escreva uma fun\u00e7\u00e3o que usa a fun\u00e7\u00e3o hash da Parte (5a) com numBuckets = $ \\scriptsize 2^{15} \\approx 33K $ para criar um `LabeledPoint` com os  hashed features armazenados como um `SparseVector`.  Ent\u00e3o use esta fun\u00e7\u00e3o para criar uma nova base de treino, valida\u00e7\u00e3o e teste com  hashed features. Dica: `parsedHashPoint` \u00e9 similar a `parseOHEPoint` da Parte (3d)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def parseHashPoint(point, numBuckets):\n",
      "    \"\"\"Create a LabeledPoint for this observation using hashing.\n",
      "\n",
      "    Args:\n",
      "        point (str): A comma separated string where the first value is the label and the rest are\n",
      "            features.\n",
      "        numBuckets: The number of buckets to hash to.\n",
      "\n",
      "    Returns:\n",
      "        LabeledPoint: A LabeledPoint with a label (0.0 or 1.0) and a SparseVector of hashed\n",
      "            features.\n",
      "    \"\"\"\n",
      "    <COMPLETAR>\n",
      "\n",
      "\n",
      "numBucketsCTR = 2 ** 15\n",
      "hashTrainData = rawTrainData.map(lambda x: parseHashPoint(x,numBucketsCTR))\n",
      "hashTrainData.cache()\n",
      "hashValidationData = rawValidationData.map(lambda x: parseHashPoint(x,numBucketsCTR))\n",
      "hashValidationData.cache()\n",
      "hashTestData = rawTestData.map(lambda x: parseHashPoint(x,numBucketsCTR))\n",
      "hashTestData.cache()\n",
      "\n",
      "print hashTrainData.take(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Creating hashed features (5b)\n",
      "hashTrainDataFeatureSum = sum(hashTrainData\n",
      "                           .map(lambda lp: len(lp.features.indices))\n",
      "                           .take(20))\n",
      "hashTrainDataLabelSum = sum(hashTrainData\n",
      "                         .map(lambda lp: lp.label)\n",
      "                         .take(100))\n",
      "hashValidationDataFeatureSum = sum(hashValidationData\n",
      "                                .map(lambda lp: len(lp.features.indices))\n",
      "                                .take(20))\n",
      "hashValidationDataLabelSum = sum(hashValidationData\n",
      "                              .map(lambda lp: lp.label)\n",
      "                              .take(100))\n",
      "hashTestDataFeatureSum = sum(hashTestData\n",
      "                          .map(lambda lp: len(lp.features.indices))\n",
      "                          .take(20))\n",
      "hashTestDataLabelSum = sum(hashTestData\n",
      "                        .map(lambda lp: lp.label)\n",
      "                        .take(100))\n",
      "\n",
      "Test.assertEquals(hashTrainDataFeatureSum, 772, 'incorrect number of features in hashTrainData')\n",
      "Test.assertEquals(hashTrainDataLabelSum, 24.0, 'incorrect labels in hashTrainData')\n",
      "Test.assertEquals(hashValidationDataFeatureSum, 776,\n",
      "                  'incorrect number of features in hashValidationData')\n",
      "Test.assertEquals(hashValidationDataLabelSum, 16.0, 'incorrect labels in hashValidationData')\n",
      "Test.assertEquals(hashTestDataFeatureSum, 774, 'incorrect number of features in hashTestData')\n",
      "Test.assertEquals(hashTestDataLabelSum, 23.0, 'incorrect labels in hashTestData')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (5c) Esparsidade **\n",
      "\n",
      "#### Uma vez que temos  33 mil hashed features contra 233 mil OHE, devemos esperar que os atributos OHE sejam mais esparsos. Verifique essa hip\u00f3tese computando a esparsidade m\u00e9dia do OHE e do hashed features.\n",
      "\n",
      "#### Note que se voc\u00ea tem um `SparseVector` chamado `sparse`, chamar `len(sparse)` retornar\u00e1 o total de atributos, e n\u00e3o o n\u00famero de valores n\u00e3o nulos. `SparseVector` tem atributos `indices` e `values` que cont\u00e9m informa\u00e7\u00f5es sobre quais atributos s\u00e3o n\u00e3o nulos. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def computeSparsity(data, d, n):\n",
      "    \"\"\"Calculates the average sparsity for the features in an RDD of LabeledPoints.\n",
      "\n",
      "    Args:\n",
      "        data (RDD of LabeledPoint): The LabeledPoints to use in the sparsity calculation.\n",
      "        d (int): The total number of features.\n",
      "        n (int): The number of observations in the RDD.\n",
      "\n",
      "    Returns:\n",
      "        float: The average of the ratio of features in a point to total features.\n",
      "    \"\"\"\n",
      "    return (data\n",
      "            .<COMPLETAR>\n",
      "            .<COMPLETAR>\n",
      "           )/(d*n*1.)\n",
      "\n",
      "averageSparsityHash = computeSparsity(hashTrainData, numBucketsCTR, nTrain)\n",
      "averageSparsityOHE = computeSparsity(OHETrainData, numCtrOHEFeats, nTrain)\n",
      "\n",
      "print 'Average OHE Sparsity: {0:.7e}'.format(averageSparsityOHE)\n",
      "print 'Average Hash Sparsity: {0:.7e}'.format(averageSparsityHash)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Sparsity (5c)\n",
      "Test.assertTrue(np.allclose(averageSparsityOHE, 1.6717677e-04),\n",
      "                'incorrect value for averageSparsityOHE')\n",
      "Test.assertTrue(np.allclose(averageSparsityHash, 1.1805561e-03),\n",
      "                'incorrect value for averageSparsityHash')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (5d) Modelo log\u00edstico com hashed features **\n",
      "\n",
      "#### Agora treine um modelo de regress\u00e3o log\u00edstica para os hashed features. Execute um grid search para encontrar par\u00e2metros adequados para essa base, avaliando o log-loss no conjunto de valida\u00e7\u00e3o. Nota: isso pode demorar alguns minutos para terminar. Use `stepSizes` de 1 e 10 e `regParams`  de 1e-6 e 1e-3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numIters = 500\n",
      "regType = 'l2'\n",
      "includeIntercept = True\n",
      "\n",
      "# Initialize variables using values from initial model training\n",
      "bestModel = None\n",
      "bestLogLoss = 1e10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "stepSizes = [1, 10]\n",
      "regParams = [1e-6, 1e-3]\n",
      "for stepSize in stepSizes:\n",
      "    for regParam in regParams:\n",
      "        model = (<COMPLETAR>)\n",
      "        logLossVa = <COMPLETAR>\n",
      "        print ('\\tstepSize = {0:.1f}, regParam = {1:.0e}: logloss = {2:.3f}'\n",
      "               .format(stepSize, regParam, logLossVa))\n",
      "        if (logLossVa < bestLogLoss):\n",
      "            bestModel = model\n",
      "            bestLogLoss = logLossVa\n",
      "\n",
      "print ('Hashed Features Validation Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
      "       .format(logLossValBase, bestLogLoss))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Logistic model with hashed features (5d)\n",
      "Test.assertTrue(np.allclose(bestLogLoss, 0.4481683608), 'incorrect value for bestLogLoss')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (5e) Avaliando a base de testes **\n",
      "\n",
      "#### Finalmente, avalie o melhor modelo da Parte (5d) na base de testes. Compare o log-loss do resultado com o log-loss do nosso baseline no conjunto de testes, calculando da mesma forma que na Parte (4f)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "# Log loss for the best model from (5d)\n",
      "logLossValLR0 = <COMPLETAR>\n",
      "\n",
      "logLossTest = <COMPLETAR>\n",
      "\n",
      "# Log loss for the baseline model\n",
      "logLossTestBaseline = hashTestData.map(lambda lp: computeLogLoss(classOneFracTrain,lp.label)).mean()\n",
      "\n",
      "print ('Hashed Features Test Log Loss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
      "       .format(logLossTestBaseline, logLossTest))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Evaluate on the test set (5e)\n",
      "Test.assertTrue(np.allclose(logLossTestBaseline, 0.537438),\n",
      "                'incorrect value for logLossTestBaseline')\n",
      "Test.assertTrue(np.allclose(logLossTest, 0.455616931), 'incorrect value for logLossTest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
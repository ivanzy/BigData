{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "",
  "signature": "sha256:e16d70ab2297410ce712e35a4898934cfa06963497bc34ae98ddf5122d712d79"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![CMCC](http://cmcc.ufabc.edu.br/images/logo_site.jpg)\n",
      "# ** An\u00e1lise Explorat\u00f3ria **\n",
      "\n",
      "#### Esse notebook introduz os conceitos de An\u00e1lise Explorat\u00f3ria\n",
      "\n",
      "#### Para isso utilizaremos a base de dados de [Crimes de S\u00e3o Francisco](https://www.kaggle.com/c/sf-crime) obtidos do site de competi\u00e7\u00f5es [Kaggle](https://www.kaggle.com/).\n",
      "\n",
      "#### ** Esse notebook cont\u00e9m:  **\n",
      "#### *Parte 1:* *Parsing* da base de dados de Crimes de S\u00e3o Francisco\n",
      "#### *Parte 2:* Estat\u00edsticas B\u00e1sicas das Vari\u00e1veis\n",
      "#### *Parte 3:* Plotagem de Gr\u00e1ficos\n",
      "\n",
      "#### Para os exerc\u00edcios \u00e9 aconselh\u00e1vel consultar a documenta\u00e7\u00e3o da [API do PySpark](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "collapsed": true
     },
     "source": [
      "** Parte 1: Parsing da Base de Dados **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Nessa primeira parte do notebook vamos aprender a trabalhar com arquivos CSV. Os arquivos CSV s\u00e3o arquivos textos representando tabelas de dados, num\u00e9ricas ou categ\u00f3ricas, com formata\u00e7\u00e3o apropriada para a leitura estruturada.\n",
      "\n",
      "#### A primeira linha de um arquivo CSV \u00e9 o cabe\u00e7alho, com o nome de cada coluna da tabela separados por v\u00edrgulas.\n",
      "\n",
      "#### Cada linha subsequente representa um objeto da base de dados com os valores tamb\u00e9m separados por v\u00edrgula. Esses valores podem ser num\u00e9ricos, categ\u00f3ricos (textuais) e listas. As listas s\u00e3o representadas por listas de valores separadas por v\u00edrgulas e entre aspas.\n",
      "\n",
      "#### Vamos carregar a base de dados hist\u00f3rica de Crimes de S\u00e3o Francisco, um dos temas do projeto final. No primeiro passo vamos armazenar o cabe\u00e7alho em uma vari\u00e1vel chamada `header` e imprimi-la para a descri\u00e7\u00e3o dos campos de nossa base."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "\n",
      "filename = os.path.join(\"Data\",\"Aula03\",\"Crime.csv\")\n",
      "CrimeRDD = sc.textFile(filename,8)\n",
      "header = CrimeRDD.take(1)[0] # o cabe\u00e7alho \u00e9 a primeira linha do arquivo\n",
      "\n",
      "print \"Campos dispon\u00edveis: {}\".format(header)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Durante os exerc\u00edcios precisaremos pular a linha do cabe\u00e7alho de tal forma a trabalhar apenas com a tabela de dados.\n",
      "\n",
      "#### Uma forma de fazer isso \u00e9 utilizando o comando `filter()` para eliminar toda linha igual a vari\u00e1vel `header`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "CrimeHeadlessRDD =  CrimeRDD.filter(lambda x: x!=header)\n",
      "\n",
      "firstObject = CrimeHeadlessRDD.take(1)[0]\n",
      "print firstObject"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert firstObject==u'2015-05-13 23:53:00,WARRANTS,WARRANT ARREST,Wednesday,NORTHERN,\"ARREST, BOOKED\",OAK ST / LAGUNA ST,-122.425891675136,37.7745985956747', 'valor incorreto'\n",
      "print \"OK\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Agora temos um dataset em que cada linha \u00e9 uma string contendo todos os valores. Por\u00e9m, para explorarmos os dados precisamos que cada objeto seja uma lista de valores.\n",
      "\n",
      "#### Utilize o comando `split()` para transformar os objetos em listas de strings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "CrimeHeadlessRDD =  CrimeRDD.filter(lambda x: x!=header)\n",
      "\n",
      "CrimeHeadlessRDD = CrimeHeadlessRDD.flatMap(lambda x: x.split(','))\n",
      "firstObjectList = CrimeHeadlessRDD.take(1)[0]\n",
      "print firstObjectList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert firstObjectList[0]==u'2015-05-13 23:53:00', 'valores incorretos'\n",
      "print \"OK\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Reparem que o campo *Resolution* cujo valor no primeiro registro era \"ARREST, BOOKED\" se tornou dois campos diferentes por causa do `split()`.\n",
      "\n",
      "#### Nesses casos em que uma simples separa\u00e7\u00e3o n\u00e3o funciona, n\u00f3s podemos utilizar as [Express\u00f5es Regulares](http://www.rexegg.com/regex-quickstart.html). O Python tem suporte as Regex atrav\u00e9s da biblioteca `re`. Vamos utilizar o comando [`re.split()`](https://docs.python.org/2/library/re.html#re.split) para cuidar da separa\u00e7\u00e3o de nossa base em campos.\n",
      "\n",
      "#### Al\u00e9m disso, vamos aproveitar para converter o primeiro campo, que representa data e hora, para objeto do tipo [`datetime`](https://docs.python.org/2/library/datetime.html) atrav\u00e9s do comando `datetime.datetime.strptime()`. Tamb\u00e9m vamos agrupar as coordenadas X e Y em uma tupla de floats.\n",
      "\n",
      "#### Outra ajuda que o Python pode nos dar \u00e9 a utiliza\u00e7\u00e3o das [`namedtuple`](https://docs.python.org/2/library/collections.html#namedtuple-factory-function-for-tuples-with-named-fields) que permite acessar cada campo de cada objeto pelo nome. Ex.: rec.Dates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "import re\n",
      "import datetime\n",
      "from collections import namedtuple\n",
      "\n",
      "headeritems = header.split(',') # transformar o cabe\u00e7alho em lista\n",
      "del headeritems[-1] # apagar o \u00faltimo item e...\n",
      "headeritems[-1] = 'COORD' # transformar em COORD\n",
      "\n",
      "# Dates,Category,Descript,DayOfWeek,PdDistrict,Resolution,Address,COORD\n",
      "Crime = namedtuple('Crime',headeritems) # gera a namedtuple Crime com os campos de header\n",
      "\n",
      "REGEX = r',(?=(?:[^\"]*\"[^\"]*\")*(?![^\"]*\"))'\n",
      "# buscar por \",\" tal que ap\u00f3s essa v\u00edrgula (?=) ou exista um par de \"\" ou n\u00e3o tenha \" sozinha\n",
      "# ?= indica para procurarmos pelo padr\u00e3o ap\u00f3s a v\u00edrgula\n",
      "# ?: significa para n\u00e3o interpretar os par\u00eanteses como captura de valores\n",
      "# [^\"]* 0 ou sequ\u00eancias de caracteres que n\u00e3o sejam aspas\n",
      "# [^\"]*\"[^\"]*\"  <qualquer caracter exceto aspas> \" <qualquer caracter exceto aspas> \"\n",
      "# ?! indica para verificar se n\u00e3o existe tal padr\u00e3o a frente da v\u00edrgula\n",
      "\n",
      "\n",
      "def ParseCrime(rec):\n",
      "    Date, Category, Descript, DayOfWeek, PdDistrict, Resolution, Address, X, Y = re.split(REGEX, rec)\n",
      "    Date = datetime.datetime.strptime(Date, \"%Y-%m-%d %H:%M:%S\")\n",
      "    COORD = (X,Y)\n",
      "    Resolution = Resolution.split(\",\")\n",
      "    return Crime(Date, Category, Descript, DayOfWeek, PdDistrict, Resolution, Address, COORD)\n",
      "\n",
      "# Aplique a fun\u00e7\u00e3o ParseCrime para cada objeto da base\n",
      "CrimeHeadlessRDD =  (CrimeRDD.filter(lambda x: x != header).map(ParseCrime))\n",
      "\n",
      "firstClean = CrimeHeadlessRDD.take(1)[0]\n",
      "totalRecs = CrimeHeadlessRDD.count()\n",
      "print firstClean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert type(firstClean.Dates) is datetime.datetime and type(firstClean.Resolution) is list and type(firstClean.COORD) is tuple,'tipos incorretos'\n",
      "print \"OK\"\n",
      "\n",
      "assert CrimeHeadlessRDD.filter(lambda x: len(x)!=8).count()==0, 'algo deu errado!'\n",
      "print \"OK\"\n",
      "\n",
      "assert totalRecs==878049, 'total de registros incorreto'\n",
      "print \"OK\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Parte 2: Estat\u00edsticas B\u00e1sicas das Vari\u00e1veis **"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Nessa parte do notebook vamos aprender a filtrar a base de dados para calcular estat\u00edsticas b\u00e1sicas necess\u00e1rias para a an\u00e1lise explorat\u00f3ria."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (2a) Contagem de frequ\u00eancia **\n",
      "\n",
      "#### A contagem de frequ\u00eancia \u00e9 realizada de forma similar ao exerc\u00edcio de contagem de palavras. Primeiro mapeamos a vari\u00e1vel de interesse. Como exemplo vamos gerar uma lista da quantidade total de cada tipo de crime (Category)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "CatCountRDD = (CrimeHeadlessRDD.map(lambda x: (x.Category,1)).reduce(lambda x,y: x+y))\n",
      "catCount = sorted(CatCountRDD.collect(), key=lambda x: -x[1])\n",
      "print catCount"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert catCount[0][1]==174900, 'valores incorretos'\n",
      "print \"OK\""
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "De forma similar, vamos gerar a contagem para as regi\u00f5es de S\u00e3o Francisco (PdDistrict)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "RegionCountRDD = (CrimeHeadlessRDD\n",
      "                 .map(lambda x: (x.PdDistrict,1))\n",
      "               .reduce(lambda x,y: x+y))\n",
      "                 )\n",
      "regCount = sorted(RegionCountRDD.collect(), key=lambda x: -x[1])\n",
      "print regCount"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert regCount[0][1]==157182, 'valores incorretos'\n",
      "print \"OK\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(2b) C\u00e1lculo da M\u00e9dia**\n",
      "\n",
      "#### Nesse exerc\u00edcio vamos calcular a m\u00e9dia de crimes em cada regi\u00e3o para cada dia da semana. Para isso, primeiro devemos calcular a quantidade de dias de cada dia da semana que existem na base de dados, para isso vamos criar uma RDD de tuplas em que o primeiro campo \u00e9 a tupla da data no formato 'dia-mes-ano' e do dia da semana e o segundo campo o valor $1$.\n",
      "\n",
      "#### Em seguida, reduzimos a RDD sem efetuar a soma, mantendo o valor $1$. Essa redu\u00e7\u00e3o filtra a RDD para que cada data apare\u00e7a uma \u00fanica vez. Ao final,  podemos efetuar o mapeamento de (DayOfWeek,1) e redu\u00e7\u00e3o com soma para contabilizar quantas vezes cada dia da semana aparece na base de dados.\n",
      "\n",
      "#### Nossa pr\u00f3xima RDD ter\u00e1 como chave uma tupla ( (DayOfWeek, PdDistrict), 1) para contabilizar quantos crimes ocorreram em determinada regi\u00e3o e naquele dia da semana. Ap\u00f3s a redu\u00e7\u00e3o, devemos mapear esse RDD para (DayOfWeek, (PdDistrict, contagem)).\n",
      "\n",
      "#### Finalmente, podemos juntar as duas RDDs uma vez que elas possuem a mesma chave (DayOfWeek), dessa forma teremos tuplas no formato ( DayOfWeek, ( (PdDistrict,contagem), contagemDiaDaSemana ) ). Isso deve ser mapeado para:\n",
      "\n",
      "#### ( DayOfWeek, ( PdDistrict, contagem / contagemDiaDaSemana ) )\n",
      "\n",
      "#### Lembrando de converter `contagemDiaDaSemana` para `float`. Finalmente, o resultado pode ser agrupado pela chave, gerando uma tupla ( DayOfWeek, [ (Pd1, media1), (Pd2, media2), ... ] ). Essa lista pode ser mapeada para um dicion\u00e1rio com o comando `dict`.\n",
      "\n",
      "#### No final, transformamos o RDD em um dicion\u00e1rio Python com o comando `collectAsMap()`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "from operator import add\n",
      "\n",
      "# Dates,Category,Descript,DayOfWeek,PdDistrict,Resolution,Address,COORD\n",
      "\n",
      "# Lambda para converter um datetime em `Dia-Mes-Ano`\n",
      "day2str = lambda x: '{}-{}-{}'.format(x.day,x.month,x.year)\n",
      "\n",
      "totalDatesRDD = (CrimeHeadlessRDD.map(lambda x: ((day2str(x.Dates), x.DayOfWeek),1)\n",
      "                                      .reduceByKey(lambda x,y: x)\n",
      "                                      .map(lambda x: (x[0][1], x[1])) \n",
      "                                      .reduceByKey(lambda x,y: x+y)))\n",
      "\n",
      "\n",
      "crimesWeekDayRegionRDD = (CrimeHeadlessRDD\n",
      "                           .map(lambda x: ((x.DayOfWeek, x.PdDistrict),1))\n",
      "                           .reduceByKey(lambda x,y: x+y)\n",
      "                           .map(lambda x: ())\n",
      "                          )\n",
      "\n",
      "RegionAvgPerDayRDD = (crimesWeekDayRegionRDD\n",
      "                      .join(totalDatesRDD)\n",
      "                      .reduceByKey(lambda x: (x[0],(x[1][0][0],x[1][0][1]/float(x[1][1]))))\n",
      "                      .groubByKey()\n",
      "                      .map(lambda x: (x[0], dict(x[1])))\n",
      "                     )\n",
      "\n",
      "RegionAvg = RegionAvgPerDayRDD.collectAsMap()\n",
      "print RegionAvg['Sunday']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert np.round(RegionAvg['Sunday']['BAYVIEW'],2)==37.27, 'valores incorretos {}'.format(np.round(RegionAvg[0][2],2))\n",
      "print \"OK\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (2c) M\u00e9dia e Desvio-Padr\u00e3o pelo PySpark **\n",
      "\n",
      "#### Uma alternativa para calcular m\u00e9dia, desvio-padr\u00e3o e outros valores descritivos \u00e9 utilizando os comandos internos do Spark. Para isso \u00e9 necess\u00e1rio gerar uma RDD de listas de valores.\n",
      "\n",
      "#### Gere uma RDD contendo a tupla ( (Dates,DayOfWeek, PdDistrict), contagem), mapeie para ( (DayOfWeek,PdDistrict), Contagem) e agrupe pela chave. Isso ir\u00e1 gerar uma RDD ( (DayOfWeek,PdDistrict), Iterador(contagens) ).\n",
      "\n",
      "#### Agora crie um dicion\u00e1rio RegionAvgSpark, inicialmente vazio e colete apenas o primeiro elemento da tupla para a vari\u00e1vel `Keys`. Itere essa vari\u00e1vel realizando os seguintes passos:\n",
      "\n",
      "* #### Se `key[0]` n\u00e3o existir no dicion\u00e1rio, crie a entrada `key[0]` como um dicion\u00e1rio vazio.\n",
      "* #### Mapeie countWeekDayDistRDD filtrando por `key` e gerando a RDD com os valores da tupla. Note que n\u00e3o queremos uma lista de listas.\n",
      "* #### Insira a tupla (media, desvio-padr\u00e3o) utilizando os comandos `mean()` e `stdev()` do PySpark, armazenando na chave RegionAvgSpark[ key[0] ][ key[1] ]."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "countWeekDayDistRDD = CrimeHeadlessRDD\n",
      "                        .map(lambda x: ((day2str(x.Dates), x.DayOfWeek,x.PdDistrict),1))\n",
      "                        .reduceByKey(lambda x,y:x+y)\n",
      "                        .map(lambda ((Dates,DayOfWeek, PdDistrict), contagem):((DayOfWeek,PdDistrict), contagem))\n",
      "                        .groupByKey()\n",
      "                       \n",
      "# Esse procedimento s\u00f3 \u00e9 vi\u00e1vel se existirem poucas chaves\n",
      "RegionAvgSpark = {}\n",
      "Keys = countWeekDayDistRDD.map(lambda rec: rec[0]).collect()\n",
      "for key in Keys:\n",
      "    listRDD = (countWeekDayDistRDD\n",
      "               .filter(lambda rec: rec[0]==key)\n",
      "               .flatMap(lambda rec: rec[1])\n",
      "               )\n",
      "    if key[0] not in RegionAvgSpark:\n",
      "        RegionAvgSpark[key[0]] = {}    \n",
      "    RegionAvgSpark[key[0]][key[1]] = (listRDD.mean(), listRDD.stdev())\n",
      "    \n",
      "print RegionAvgSpark['Sunday']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert np.round(RegionAvgSpark['Sunday']['BAYVIEW'][0],2)==37.39 and np.round(RegionAvgSpark['Sunday']['BAYVIEW'][1],2)==10.06, 'valores incorretos'\n",
      "print \"OK\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Parte 3: Plotagem de Gr\u00e1ficos"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Nessa parte do notebook vamos aprender a manipular os dados para gerar listas de valores a serem utilizados na plotagem de gr\u00e1ficos.\n",
      "\n",
      "#### Para a plotagem de gr\u00e1ficos vamos utilizar o [`matplotlib`](http://matplotlib.org/) que j\u00e1 vem por padr\u00e3o na maioria das distribui\u00e7\u00f5es do Python (ex.: Anaconda). Outras bibliotecas alternativas interessantes s\u00e3o: [Seaborn](http://stanford.edu/~mwaskom/software/seaborn/) e [Bokeh](http://bokeh.pydata.org/en/latest/)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (3a) Gr\u00e1fico de Barras **\n",
      "\n",
      "#### O gr\u00e1fico de barras \u00e9 utilizado quando queremos comparar dados entre categorias diferentes de uma vari\u00e1vel categ\u00f3rica. Como exemplo, vamos contabilizar o n\u00famero m\u00e9dio de crimes di\u00e1rios por regi\u00e3o.\n",
      "\n",
      "#### Vamos primeiro criar a RDD totalDatesRDD que cont\u00e9m a lista de dias \u00fanicos, computaremos o total de dias com o comando `count()` armazenando na vari\u00e1vel `totalDays`. N\u00e3o se esque\u00e7a de converter o valor para `float`.\n",
      "\n",
      "#### Em seguida, crie o RDD avgCrimesRegionRDD que utiliza a RDD RegionCountRDD para calcular a m\u00e9dia de crimes por regi\u00e3o.\n",
      "\n",
      "#### Utilizando o comando `zip()` do Python \u00e9 poss\u00edvel descompactar um dicion\u00e1rio em duas vari\u00e1veis, uma com as chaves e outra com os valores. Utilizaremos essas vari\u00e1veis para a plotagem do gr\u00e1fico."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Dates,Category,Descript,DayOfWeek,PdDistrict,Resolution,Address,COORD\n",
      "\n",
      "# Lambda para converter um datetime em `Dia-Mes-Ano`\n",
      "day2str = lambda x: '{}-{}-{}'.format(x.day,x.month,x.year)\n",
      "\n",
      "totalDatesRDD = (CrimeHeadlessRDD\n",
      "                 .map(lambda rec: (day2str(rec.Dates),1))\n",
      "                 .reduceByKey(lambda x,y: x)\n",
      "                 )\n",
      "\n",
      "totalDays = float(totalDatesRDD.count())\n",
      "\n",
      "avgCrimesRegionRDD = (RegionCountRDD\n",
      "                      .map(lambda rec: (rec[0],rec[1]/totalDays))\n",
      "                     )\n",
      "\n",
      "Xticks,Y = zip(*avgCrimesRegionRDD.collectAsMap().items())\n",
      "indices = np.arange(len(Xticks))\n",
      "width = 0.35\n",
      "\n",
      "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
      "plt.bar(indices,Y, width)\n",
      "plt.grid(b=True, which='major', axis='y')\n",
      "plt.xticks(indices+width/2., Xticks, rotation=17 )\n",
      "plt.ylabel('Number of crimes')\n",
      "plt.xlabel('Region')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {
      "scrolled": false
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Quando temos subcategorias de interesse, podemos plotar atrav\u00e9s de um gr\u00e1fico de barras empilhado. Vamos plotar o conte\u00fado da vari\u00e1vel RegionAvg.\n",
      "\n",
      "#### Primeiro passo \u00e9 criar um dicion\u00e1rio `Y` em que a chave \u00e9 o dia da semana e o valor \u00e9 uma `np.array` contendo a m\u00e9dia de cada regi\u00e3o para aquele dia.\n",
      "\n",
      "#### Em seguida precisamos criar uma matriz `Bottom` que determina qual \u00e9 o in\u00edcio de cada uma das barras. O in\u00edcio da barra do dia `i` deve ser o final da barra do dia `i-1`.\n",
      "\n",
      "#### Com isso calculado podemos gerar um plot por dia com o par\u00e2metro bottom correspondente ao vetor `Bottom` daquele dia."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Dias da semana como refer\u00eancia\n",
      "Day = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']\n",
      "\n",
      "# Uma cor para cada dia\n",
      "Color = ['r','b','g','y','c','k','purple']\n",
      "\n",
      "# Dicion\u00e1rio (dia, array de m\u00e9dias)\n",
      "Y = {}\n",
      "for day in Day:\n",
      "    Y[day] = np.array([RegionAvg[day][x] for x in Xticks])\n",
      "\n",
      "# Matriz dias x regi\u00f5es    \n",
      "Bottom = np.zeros( (len(Day),len(Xticks)) )\n",
      "for i in range(1,len(Day)):\n",
      "    Bottom[i,:] = Bottom[i-1,:]+Y[Day[i-1]]\n",
      "    \n",
      "indices = np.arange(len(Xticks))\n",
      "width = 0.35\n",
      "\n",
      "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
      "\n",
      "# Gera uma lista de plots, um para cada dia\n",
      "plots = [plt.bar(indices,Y[Day[i]], width, color=Color[i], bottom=Bottom[i]) for i in range(len(Day))]\n",
      "\n",
      "plt.legend( [p[0] for p in plots], Day,loc='center left', bbox_to_anchor=(1, 0.5) ) \n",
      "    \n",
      "plt.grid(b=True, which='major', axis='y')\n",
      "plt.xticks(indices+width/2., Xticks, rotation=17 )\n",
      "plt.ylabel('Number of crimes')\n",
      "plt.xlabel('Region')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (3b) Gr\u00e1fico de Linha **\n",
      "\n",
      "#### O gr\u00e1fico de linha \u00e9 utilizado principalmente para mostrar uma tend\u00eancia temporal.\n",
      "\n",
      "#### Nesse exerc\u00edcio vamos primeiro gerar o n\u00famero m\u00e9dio de crimes em cada hora do dia.\n",
      "\n",
      "#### Primeiro, novamente, geramos um RDD contendo um \u00fanico registro de cada hora para cada dia. Em seguida, contabilizamos a soma da quantidade de crime em cada hora. Finalmente, juntamos as duas RDDs e calculamos a m\u00e9dia dos valores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "parseWeekDay = lambda x: '{}-{}-{}'.format(x.day, x.month, x.year)\n",
      "\n",
      "hoursRDD = (CrimeHeadlessRDD\n",
      "            .map(lambda x: ((parseWeekDay(x.Dates),x.Dates.hour),1))\n",
      "            .reduceByKey(lambda x,y: x)\n",
      "            .map(lambda ((date,hour),num): (hour,num))\n",
      "            .reduceByKey(lambda x,y:x+y)\n",
      "           )\n",
      "\n",
      "crimePerHourRDD = (CrimeHeadlessRDD\n",
      "                   .map(lambda x: (x.Dates.hour,1))\n",
      "                   .reduceByKey(lambda x,y:x+y)\n",
      "                  )\n",
      "\n",
      "avgCrimeHourRDD = (crimePerHourRDD\n",
      "                   .join(hoursRDD)\n",
      "                   .map(lambda (key,(num,denum)): (key,(float(num)/denum)))\n",
      "                  )\n",
      "\n",
      "crimePerHour = avgCrimeHourRDD.collect()\n",
      "print crimePerHour[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert np.round(crimePerHour[0][1],2)==19.96, 'valores incorretos'\n",
      "print \"OK\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crimePerHourSort = sorted(crimePerHour,key=lambda x: x[0])\n",
      "\n",
      "X,Y = zip(*crimePerHourSort)\n",
      "\n",
      "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
      "plt.plot(X,Y)\n",
      "plt.grid(b=True, which='major', axis='y')\n",
      "plt.ylabel('Avg. Number of crimes')\n",
      "plt.xlabel('Hour')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(3c) Gr\u00e1fico de Dispers\u00e3o**\n",
      "\n",
      "#### O gr\u00e1fico de dispers\u00e3o \u00e9 utilizado para visualizar correla\u00e7\u00f5es entre as vari\u00e1veis. Com esse gr\u00e1fico \u00e9 poss\u00edvel observar se o crescimento da quantidade de uma categoria est\u00e1 relacionada ao crescimento/decrescimento de outra (mas n\u00e3o podemos dizer se uma causa a outra).\n",
      "\n",
      "#### Na primeira parte do exerc\u00edcio calcularemos a correla\u00e7\u00e3o entre os diferentes tipos de crime. Para isso primeiro precisamos construir uma RDD em que cada registro corresponde a uma data o valor contido nele \u00e9 a quantidade de crimes de cada tipo.\n",
      "\n",
      "#### Diferente dos exerc\u00edcios anteriores, devemos manter essa informa\u00e7\u00e3o como uma lista de valores em que todos os registros sigam a mesma ordem da lista de crimes.\n",
      "\n",
      "#### O primeiro passo \u00e9 criar uma RDD com a tupla ( (Mes-Ano, Crime), 1 ) e utiliz\u00e1-la para gerar a tupla ( (Mes-Ano,Crime) Quantidade ).\n",
      "\n",
      "#### Mapeamos essa RDD para definir Mes-Ano como chave e agrupamos em torno dessa chave, gerando uma lista de quantidade de crimes em cada data. Aplicamos a fun\u00e7\u00e3o `dict()` nessa lista para obtermos uma RDD no seguinte formato: (Mes-Ano, {CRIME: quantidade}).\n",
      "\n",
      "#### Al\u00e9m disso, vamos criar a vari\u00e1vel `crimes` contendo a lista de crimes contidas na lista de pares `catCount` computada anteriormente."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "parseMonthYear = lambda x: '{}-{}'.format(x.month, x.year)\n",
      "\n",
      "crimes = map(lambda x: x[0], catCount)\n",
      "\n",
      "datesCrimesRDD = (CrimeHeadlessRDD\n",
      "                .map(lambda x:((parseMonthYear(x.Dates),x.Category),1))\n",
      "                .reduceByKey(lambda x,y: x+y)\n",
      "                .map(lambda ((x),count): (x[0],(x[1],count)))\n",
      "                .groupByKey()\n",
      "                .map(lambda (x,y): (x,dict(y)))\n",
      "                .cache()\n",
      "                 )\n",
      "\n",
      "print datesCrimesRDD.take(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert datesCrimesRDD.take(1)[0][1][u'KIDNAPPING']==12,'valores incorretos'\n",
      "print 'ok'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### O pr\u00f3ximo passo consiste em calcular o total de pares Mes-Ano para ser poss\u00edvel o c\u00e1lculo da m\u00e9dia.\n",
      "\n",
      "#### Finalmente, criamos a RDD `fractionCrimesDateRDD` em que a chave \u00e9 Mes-Ano e o valor \u00e9 uma lista da fra\u00e7\u00e3o de cada tipo de crime ocorridos naquele m\u00eas e ano. Para gerar essa lista vamos utilizar o *list comprehension* do Python de tal forma a calcular a fra\u00e7\u00e3o para cada crime na vari\u00e1vel `crimes`.\n",
      "\n",
      "#### Os dicion\u00e1rios em Python tem um m\u00e9todo chamado `get()` que permite atribuir um valor padr\u00e3o caso a chave n\u00e3o exista. Ex.: `dicionario.get( chave, 0.0)` retornar\u00e1 0.0 caso a chave n\u00e3o exista."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "totalPerDateRDD = (CrimeHeadlessRDD\n",
      "                   .map(lambda x: (parseMonthYear(x.Dates)))\n",
      "                   .distinct()\n",
      "                   .count()\n",
      "                  )\n",
      "#?\n",
      "fractionCrimesDateRDD = (datesCrimesRDD\n",
      "                         .map(lambda x: (parseMonthYear(x.Dates)))\n",
      "                         .cache()\n",
      "                        )\n",
      "\n",
      "print fractionCrimesDateRDD.take(1)"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert np.abs(fractionCrimesDateRDD.take(1)[0][1][0][1]-0.163950)<1e-6,'valores incorretos'\n",
      "print 'ok'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Finalmente, utilizaremos a fun\u00e7\u00e3o `Statistics.corr()` da biblioteca [`pyspark.mlllib.stat`](https://spark.apache.org/docs/1.1.0/api/python/pyspark.mllib.stat.Statistics-class.html).\n",
      "\n",
      "#### Para isso mapeamos nossa RDD para conter apenas a lista de valores da lista de tuplas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.stat import Statistics\n",
      "corr = Statistics.corr(fractionCrimesDateRDD.map(lambda rec: map(lambda x: x[1],rec[1])))\n",
      "print corr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Convertendo a matriz `corr` para `np.array` podemos buscar pelo maior valor negativo e positivo diferentes de 1.0. Para isso vamos utilizar as fun\u00e7\u00f5es `min()` e `argmin()`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "npCorr = np.array(corr)\n",
      "rowMin = npCorr.min(axis=1).argmin()\n",
      "colMin = npCorr[rowMin,:].argmin()\n",
      "print crimes[rowMin], crimes[colMin], npCorr[rowMin,colMin]\n",
      "\n",
      "npCorr[npCorr==1.] = 0.\n",
      "rowMax = npCorr.max(axis=1).argmax()\n",
      "colMax = npCorr[rowMax,:].argmax()\n",
      "print crimes[rowMax], crimes[colMax], npCorr[rowMax,colMax]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Agora que sabemos quais crimes tem maior correla\u00e7\u00e3o, vamos plotar um gr\u00e1fico de dispers\u00e3o daqueles com maior correla\u00e7\u00e3o negativa.\n",
      "\n",
      "#### Primeiro criamos duas RDDs, `var1RDD` e `var2RDD`. Elas s\u00e3o um mapeamento da `fractionCrimesDateRDD` filtradas para conter apenas o crime contido em Xlabel e Ylabel, respectivamente.\n",
      "\n",
      "#### Juntamos as duas RDDs em uma \u00fanica RDD, `correlationRDD` que mapear\u00e1 para tuplas de valores, onde os valores s\u00e3o as m\u00e9dias calculadas em fractionCrimesDateRDD."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "Xlabel = 'FORGERY/COUNTERFEITING'#'DRIVING UNDER THE INFLUENCE'\n",
      "Ylabel = 'NON-CRIMINAL'#'LIQUOR LAWS'\n",
      "\n",
      "\n",
      "\n",
      "var1RDD = (fractionCrimesDateRDD\n",
      "           .map(lambda rec: (rec[0], filter(lambda x: x[0]==Xlabel,rec[1])[0][1]))\n",
      "          )\n",
      "var2RDD = (fractionCrimesDateRDD\n",
      "           .map(lambda rec: (rec[0], filter(lambda x: x[0]==Ylabel,rec[1])[0][1]))\n",
      "          )\n",
      "\n",
      "correlationRDD = (var1RDD\n",
      "                  .join(var2RDD)\n",
      "                 )\n",
      "\n",
      "\n",
      "Data = correlationRDD.collect()\n",
      "print Data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert np.abs(Data[0][0]-0.015904)<1e-6, 'valores incorretos'\n",
      "print 'ok'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "No gr\u00e1fico abaixo, \u00e9 poss\u00edvel perceber que quanto mais crimes do tipo *NON-CRIMINAL* ocorrem em um dia, menos *FORGERY/COUNTERFEITING* ocorrem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,Y = zip(*Data)\n",
      "\n",
      "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
      "plt.scatter(X,Y)\n",
      "plt.grid(b=True, which='major', axis='y')\n",
      "plt.xlabel(Xlabel)\n",
      "plt.ylabel(Ylabel)\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(3d) Histograma **\n",
      "\n",
      "#### O uso do Histograma \u00e9 para visualizar a distribui\u00e7\u00e3o dos dados. Dois tipos de distribui\u00e7\u00e3o que s\u00e3o observadas normalmente \u00e9 a Gaussiana, em que os valores se concentram em torno de uma m\u00e9dia e a Lei de Pot\u00eancia, em que os valores menores s\u00e3o observados com maior frequ\u00eancia.\n",
      "\n",
      "#### Vamos verificar a distribui\u00e7\u00e3o das pris\u00f5es efetuadas (categoria *ARREST* em * Resolution*) em cada m\u00eas. Com essa distribui\u00e7\u00e3o poderemos verificar se o n\u00famero de pris\u00f5es \u00e9 consistente durante os meses do per\u00edodo estudado.\n",
      "\n",
      "#### Primeiro criaremos uma RDD chamada `bookedRDD` que cont\u00e9m apenas os registros contendo *ARREST* no campo *Resolution* (lembre-se que esse campo \u00e9 uma lista) e contabilizar a quantidade de registros em cada 'Mes-Ano'. Ao final, vamos mapear para uma RDD contendo apenas os valores contabilizados."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "bookedRDD = (CrimeHeadlessRDD\n",
      "            .filter(lambda x: u'\"ARREST' == x.Resolution[0])\n",
      "            .map(lambda x: (parseMonthYear(x.Dates),1))\n",
      "            .reduceByKey(lambda x,y:x+y)\n",
      "            .map(lambda (date, count): count))\n",
      "\n",
      "Data = bookedRDD.collect()\n",
      "print Data[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert Data[0]==1914,'valores incorretos'\n",
      "print 'ok'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
      "plt.hist(Data)\n",
      "plt.grid(b=True, which='major', axis='y')\n",
      "plt.xlabel('ARRESTED')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Notem que lemos o histograma da seguinte maneira: em cerca de 50 meses foram observadas entre 1750 e 2000 pris\u00f5es. Por\u00e9m, n\u00e3o sabemos precisar em quais meses houve um aumento ou redu\u00e7\u00e3o das pris\u00f5es. Isso deve ser observado atrav\u00e9s de um gr\u00e1fico de linha."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(3e) Box-plot**\n",
      "\n",
      "#### O Box-plot \u00e9 um gr\u00e1fico muito utilizado em estat\u00edstica para visualizar o resumo estat\u00edstico de uma vari\u00e1vel.\n",
      "\n",
      "#### Para esse exerc\u00edcio vamos plotar duas box-plot sobre a m\u00e9dia do n\u00famero de pris\u00f5es durante os meses analisados para os crimes do tipo *ROBBERY* e *ASSAULT*.\n",
      "\n",
      "#### O mapeamento \u00e9 exatamente o mesmo do exerc\u00edcio anterior, por\u00e9m filtrando para o tipo de roubo analisado."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# EXERCICIO\n",
      "\n",
      "parseDayMonth = lambda x: '{}-{}'.format(x.month,x.year)\n",
      "\n",
      "robberyBookedRDD = (CrimeHeadlessRDD\n",
      "                    .filter(lambda x: 'ROBBERY' == x.Category)\n",
      "                    .map(lambda x: (parseDayMonth(x.Dates),1))\n",
      "                    .reduceByKey(lambda x,y:x+y)\n",
      "                    .map(lambda (date, count): count))\n",
      "                   \n",
      "\n",
      "assaultBookedRDD = (CrimeHeadlessRDD\n",
      "                    .filter(lambda x: 'ASSAULT' == x.Category)\n",
      "                    .map(lambda x: (parseDayMonth(x.Dates),1))\n",
      "                    .reduceByKey(lambda x,y:x+y)\n",
      "                    .map(lambda (date, count): count))\n",
      "\n",
      "robData = robberyBookedRDD.collect()\n",
      "assData = assaultBookedRDD.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert robData[0]==27,'valores incorretos'\n",
      "print 'ok'\n",
      "assert assData[0]==152,'valores incorretos'\n",
      "print 'ok'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "No gr\u00e1fico abaixo, percebemos que existem, em m\u00e9dia, muito mais pris\u00f5es para o tipo *ASSAULT* do que o tipo *ROBBERY*, ambos com pequena varia\u00e7\u00e3o."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
      "plt.boxplot([robData,assData])\n",
      "plt.grid(b=True, which='major', axis='y')\n",
      "plt.ylabel('ARRESTED')\n",
      "plt.xticks([1,2], ['ROBBERY','ASSAULT'])\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
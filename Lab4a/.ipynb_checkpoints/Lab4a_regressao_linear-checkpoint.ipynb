{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "",
  "signature": "sha256:2c7a1ad085ecd27e05ff8157b2ab824bd2d763bed19bbafaa9cf944cebf1489e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![CMCC](http://cmcc.ufabc.edu.br/images/logo_site.jpg)\n",
      "# **Regress\u00e3o Linear**\n",
      "\n",
      "#### Este notebook mostra uma implementa\u00e7\u00e3o b\u00e1sica de Regress\u00e3o Linear e o uso da biblioteca [MLlib](http://spark.apache.org/docs/1.4.0/api/python/pyspark.ml.html) do PySpark para a tarefa de regress\u00e3o na base de dados [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) do reposit\u00f3rio [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Nosso objetivo \u00e9 predizer o ano de uma m\u00fasica atrav\u00e9s dos seus atributos de \u00e1udio.\n",
      "\n",
      "#### ** Neste notebook: **\n",
      "+  ####*Parte 1:* Leitura e *parsing* da base de dados\n",
      " + #### *Visualiza\u00e7\u00e3o 1:* Atributos\n",
      " + #### *Visualiza\u00e7\u00e3o 2:* Deslocamento das vari\u00e1veis de interesse\n",
      "+  ####*Parte 2:* Criar um preditor de refer\u00eancia\n",
      " + #### *Visualiza\u00e7\u00e3o 3:* Valores Preditos vs. Verdadeiros\n",
      "+  ####*Parte 3:* Treinar e avaliar um modelo de regress\u00e3o linear\n",
      " + #### *Visualiza\u00e7\u00e3o 4:* Erro de Treino\n",
      "+  ####*Parte 4:* Treinar usando MLlib e ajustar os hiperpar\u00e2metros\n",
      " + #### *Visualiza\u00e7\u00e3o 5:* Predi\u00e7\u00f5es do Melhor modelo\n",
      " + #### *Visualiza\u00e7\u00e3o 6:* Mapa de calor dos hiperpar\u00e2metros\n",
      "+  ####*Parte 5:* Adicionando intera\u00e7\u00f5es entre atributos\n",
      "+  ####*Parte 6:* Aplicando na base de dados de Crimes de S\u00e3o Francisco\n",
      " \n",
      "#### Para refer\u00eancia, consulte os m\u00e9todos relevantes do PySpark em [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) e do NumPy em [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Parte 1: Leitura e *parsing* da base de dados**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (1a) Verificando os dados dispon\u00edveis **\n",
      "\n",
      "#### Os dados da base que iremos utilizar est\u00e3o armazenados em um arquivo texto. No primeiro passo vamos transformar os dados textuais em uma RDD e verificar a formata\u00e7\u00e3o dos mesmos. Altere a segunda c\u00e9lula para verificar quantas amostras existem nessa base de dados utilizando o m\u00e9todo  [count method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.count).\n",
      "\n",
      "#### Reparem que o r\u00f3tulo dessa base \u00e9 o primeiro registro, representando o ano."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# carregar base de dados\n",
      "from test_helper import Test\n",
      "import os.path\n",
      "baseDir = os.path.join('Data')\n",
      "inputPath = os.path.join('Aula04', 'millionsong.txt')\n",
      "fileName = os.path.join(baseDir, inputPath)\n",
      "\n",
      "numPartitions = 2\n",
      "rawData = sc.textFile(fileName, numPartitions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "numPoints = rawData.count()\n",
      "print numPoints\n",
      "samplePoints = rawData.take(5)\n",
      "print samplePoints"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Load and check the data (1a)\n",
      "Test.assertEquals(numPoints, 6724, 'incorrect value for numPoints')\n",
      "Test.assertEquals(len(samplePoints), 5, 'incorrect length for samplePoints')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (1b) Usando `LabeledPoint` **\n",
      "#### Na MLlib, bases de dados rotuladas devem ser armazenadas usando o objeto [LabeledPoint](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint).  Escreva a fun\u00e7\u00e3o `parsePoint` que recebe como entrada uma amostra de dados, transforma os dados usandoo comando [unicode.split](https://docs.python.org/2/library/string.html#string.split), e retorna um `LabeledPoint`.  \n",
      "\n",
      "#### Aplique essa fun\u00e7\u00e3o na vari\u00e1vel `samplePoints` da c\u00e9lula anterior e imprima os atributos e r\u00f3tulo utilizando os atributos `LabeledPoint.features` e `LabeledPoint.label`. Finalmente, calcule o n\u00famero de atributos nessa base de dados."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.regression import LabeledPoint\n",
      "import numpy as np\n",
      "\n",
      "# Here is a sample raw data point:\n",
      "# '2001.0,0.884,0.610,0.600,0.474,0.247,0.357,0.344,0.33,0.600,0.425,0.60,0.419'\n",
      "# In this raw data point, 2001.0 is the label, and the remaining values are features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def parsePoint(line):\n",
      "    \"\"\"Converts a comma separated unicode string into a `LabeledPoint`.\n",
      "\n",
      "    Args:\n",
      "        line (unicode): Comma separated unicode string where the first element is the label and the\n",
      "            remaining elements are features.\n",
      "\n",
      "    Returns:\n",
      "        LabeledPoint: The line is converted into a `LabeledPoint`, which consists of a label and\n",
      "            features.\n",
      "    \"\"\"\n",
      "    Point = LabeledPoint(line.split(\",\")[0], line.split(\",\")[2:])\n",
      "    return (Point)\n",
      "\n",
      "parsedSamplePoints = map(parsePoint,samplePoints)\n",
      "firstPointFeatures = parsedSamplePoints[0].features\n",
      "firstPointLabel = parsedSamplePoints[0].label\n",
      "print firstPointFeatures, firstPointLabel\n",
      "\n",
      "d = len(firstPointFeatures)\n",
      "print d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Using LabeledPoint (1b)\n",
      "Test.assertTrue(isinstance(firstPointLabel, float), 'label must be a float')\n",
      "expectedX0 = [0.8841,0.6105,0.6005,0.4747,0.2472,0.3573,0.3441,0.3396,0.6009,0.4257,0.6049,0.4192]\n",
      "Test.assertTrue(np.allclose(expectedX0, firstPointFeatures, 1e-4, 1e-4),\n",
      "                'incorrect features for firstPointFeatures')\n",
      "Test.assertTrue(np.allclose(2001.0, firstPointLabel), 'incorrect label for firstPointLabel')\n",
      "Test.assertTrue(d == 12, 'incorrect number of features')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **Visualiza\u00e7\u00e3o 1: Atributos**\n",
      "\n",
      "#### A pr\u00f3xima c\u00e9lula mostra uma forma de visualizar os atributos atrav\u00e9s de um mapa de calor. Nesse mapa mostramos os 50 primeiros objetos e seus atributos representados por tons de cinza, sendo o branco representando o valor 0 e o preto representando o valor 1.\n",
      "\n",
      "#### Esse tipo de visualiza\u00e7\u00e3o ajuda a perceber a varia\u00e7\u00e3o dos valores dos atributos."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cm\n",
      "\n",
      "sampleMorePoints = rawData.take(50)\n",
      "\n",
      "parsedSampleMorePoints = map(parsePoint, sampleMorePoints)\n",
      "dataValues = map(lambda lp: lp.features.toArray(), parsedSampleMorePoints)\n",
      "\n",
      "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
      "                gridWidth=1.0):\n",
      "    \n",
      "    \"\"\"Template for generating the plot layout.\"\"\"\n",
      "    plt.close()\n",
      "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
      "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
      "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
      "        axis.set_ticks_position('none')\n",
      "        axis.set_ticks(ticks)\n",
      "        axis.label.set_color('#999999')\n",
      "        if hideLabels: axis.set_ticklabels([])\n",
      "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
      "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
      "    return fig, ax\n",
      "\n",
      "# generate layout and plot\n",
      "fig, ax = preparePlot(np.arange(.5, 11, 1), np.arange(.5, 49, 1), figsize=(8,7), hideLabels=True,\n",
      "                      gridColor='#eeeeee', gridWidth=1.1)\n",
      "image = plt.imshow(dataValues,interpolation='nearest', aspect='auto', cmap=cm.Greys)\n",
      "for x, y, s in zip(np.arange(-.125, 12, 1), np.repeat(-.75, 12), [str(x) for x in range(12)]):\n",
      "    plt.text(x, y, s, color='#999999', size='10')\n",
      "plt.text(4.7, -3, 'Feature', color='#999999', size='11'), ax.set_ylabel('Observation')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(1c) Deslocando os r\u00f3tulos **\n",
      "\n",
      "#### Para melhor visualizar as solu\u00e7\u00f5es obtidas, calcular o erro de predi\u00e7\u00e3o e visualizar a rela\u00e7\u00e3o dos atributos com os r\u00f3tulos, costuma-se deslocar os r\u00f3tulos para iniciarem em zero.\n",
      "\n",
      "#### Dessa forma vamos verificar qual \u00e9 a faixa de valores dos r\u00f3tulos e, em seguida, subtrair os r\u00f3tulos pelo menor valor encontrado. Em alguns casos tamb\u00e9m pode ser interessante normalizar tais valores dividindo pelo valor m\u00e1ximo dos r\u00f3tulos."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO \n",
      "def parseLabel(line):\n",
      "    return (line.split(\",\")[0])\n",
      "parsedDataInit = rawData.map(parsePoint)\n",
      "onlyLabels = rawData.map(parseLabel)\n",
      "minYear = onlyLabels.min()\n",
      "maxYear = onlyLabels.max()\n",
      "print maxYear, minYear"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Find the range (1c)\n",
      "Test.assertEquals(len(parsedDataInit.take(1)[0].features), 12,\n",
      "                  'unexpected number of features in sample point')\n",
      "sumFeatTwo = parsedDataInit.map(lambda lp: lp.features[2]).sum()\n",
      "Test.assertTrue(np.allclose(sumFeatTwo, 3158.96224351), 'parsedDataInit has unexpected values')\n",
      "yearRange = maxYear - minYear\n",
      "Test.assertTrue(yearRange == 89, 'incorrect range for minYear to maxYear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "minYear = (float) minYear\n",
      "parsedData = parsedDataInit.map(lambda x : LabeledPoint(x.label-minYear,x.features))\n",
      "\n",
      "# Should be a LabeledPoint\n",
      "print type(parsedData.take(1)[0])\n",
      "# View the first point\n",
      "print '\\n{0}'.format(parsedData.take(1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Shift labels (1d)\n",
      "oldSampleFeatures = parsedDataInit.take(1)[0].features\n",
      "newSampleFeatures = parsedData.take(1)[0].features\n",
      "Test.assertTrue(np.allclose(oldSampleFeatures, newSampleFeatures),\n",
      "                'new features do not match old features')\n",
      "sumFeatTwo = parsedData.map(lambda lp: lp.features[2]).sum()\n",
      "Test.assertTrue(np.allclose(sumFeatTwo, 3158.96224351), 'parsedData has unexpected values')\n",
      "minYearNew = parsedData.map(lambda lp: lp.label).min()\n",
      "maxYearNew = parsedData.map(lambda lp: lp.label).max()\n",
      "Test.assertTrue(minYearNew == 0, 'incorrect min year in shifted data')\n",
      "Test.assertTrue(maxYearNew == 89, 'incorrect max year in shifted data')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (1d) Conjuntos de treino, valida\u00e7\u00e3o e teste **\n",
      "\n",
      "#### Como pr\u00f3ximo passo, vamos dividir nossa base de dados em conjunto de treino, valida\u00e7\u00e3o e teste conforme discutido em sala de aula. Use o m\u00e9todo [randomSplit method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) com os pesos (weights) e a semente aleat\u00f3ria (seed) especificados na c\u00e9lula abaixo parar criar a divis\u00e3o das bases. Em seguida, utilizando o m\u00e9todo `cache()` fa\u00e7a o pr\u00e9-armazenamento da base processada.\n",
      "\n",
      "#### Esse comando faz o processamento da base atrav\u00e9s das transforma\u00e7\u00f5es e armazena em um novo RDD que pode ficar armazenado em mem\u00f3ria, se couber, ou em um arquivo tempor\u00e1rio."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "weights = [.8, .1, .1]\n",
      "seed = 42\n",
      "parsedTrainData, parsedValData, parsedTestData = parsedData.randomSplit(weights,seed)\n",
      "\n",
      "parsedTrainData.cache()\n",
      "parsedValData.cache()\n",
      "parsedTestData.cache()\n",
      "nTrain = parsedTrainData.count()\n",
      "nVal = parsedValData.count()\n",
      "nTest = parsedTestData.count()\n",
      "\n",
      "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
      "print parsedData.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Training, validation, and test sets (1e)\n",
      "Test.assertEquals(parsedTrainData.getNumPartitions(), numPartitions,\n",
      "                  'parsedTrainData has wrong number of partitions')\n",
      "Test.assertEquals(parsedValData.getNumPartitions(), numPartitions,\n",
      "                  'parsedValData has wrong number of partitions')\n",
      "Test.assertEquals(parsedTestData.getNumPartitions(), numPartitions,\n",
      "                  'parsedTestData has wrong number of partitions')\n",
      "Test.assertEquals(len(parsedTrainData.take(1)[0].features), 12,\n",
      "                  'parsedTrainData has wrong number of features')\n",
      "sumFeatTwo = (parsedTrainData\n",
      "              .map(lambda lp: lp.features[2])\n",
      "              .sum())\n",
      "sumFeatThree = (parsedValData\n",
      "                .map(lambda lp: lp.features[3])\n",
      "                .reduce(lambda x, y: x + y))\n",
      "sumFeatFour = (parsedTestData\n",
      "               .map(lambda lp: lp.features[4])\n",
      "               .reduce(lambda x, y: x + y))\n",
      "Test.assertTrue(np.allclose([sumFeatTwo, sumFeatThree, sumFeatFour],\n",
      "                            2526.87757656, 297.340394298, 184.235876654),\n",
      "                'parsed Train, Val, Test data has unexpected values')\n",
      "Test.assertTrue(nTrain + nVal + nTest == 6724, 'unexpected Train, Val, Test data set size')\n",
      "Test.assertEquals(nTrain, 5371, 'unexpected value for nTrain')\n",
      "Test.assertEquals(nVal, 682, 'unexpected value for nVal')\n",
      "Test.assertEquals(nTest, 671, 'unexpected value for nTest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Part 2: Criando o modelo de *baseline* **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(2a) R\u00f3tulo m\u00e9dio **\n",
      "\n",
      "#### O baseline \u00e9 \u00fatil para verificarmos que nosso modelo de regress\u00e3o est\u00e1 funcionando. Ele deve ser um modelo bem simples que qualquer algoritmo possa fazer melhor.\n",
      "\n",
      "#### Um baseline muito utilizado \u00e9 fazer a mesma predi\u00e7\u00e3o independente dos dados analisados utilizando o r\u00f3tulo m\u00e9dio do conjunto de treino. Calcule a m\u00e9dia dos r\u00f3tulos deslocados para a base de treino, utilizaremos esse valor posteriormente para comparar o erro de predi\u00e7\u00e3o.  Use um m\u00e9todo apropriado para essa tarefa, consulte o [RDD API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "averageTrainYear = parsedTrainData.map(lambda x:  (x.label,1))\n",
      "averageTrainYear = averageTrainYear.reduce(lambda (x1,y1), (x2,y2): (x1+x2,y1+y2))\n",
      "averageTrainYear = averageTrainYear[0]/averageTrainYear[1]\n",
      "\n",
      "print averageTrainYear"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Average label (2a)\n",
      "Test.assertTrue(np.allclose(averageTrainYear, 53.9316700801),\n",
      "                'incorrect value for averageTrainYear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(2b) Erro quadr\u00e1tico m\u00e9dio **\n",
      "\n",
      "#### Para comparar a performance em problemas de regress\u00e3o, geralmente \u00e9 utilizado o Erro Quadr\u00e1tico M\u00e9dio ([RMSE](http://en.wikipedia.org/wiki/Root-mean-square_deviation)).  Implemente uma fun\u00e7\u00e3o que calcula o RMSE a partir de um RDD de tuplas (r\u00f3tulo, predi\u00e7\u00e3o)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def squaredError(label, prediction):\n",
      "    \"\"\"Calculates the the squared error for a single prediction.\n",
      "\n",
      "    Args:\n",
      "        label (float): The correct value for this observation.\n",
      "        prediction (float): The predicted value for this observation.\n",
      "\n",
      "    Returns:\n",
      "        float: The difference between the `label` and `prediction` squared.\n",
      "    \"\"\"\n",
      "    return ((prediction-label)**2)\n",
      "\n",
      "\n",
      "def calcRMSE(labelsAndPreds):\n",
      "    \"\"\"Calculates the root mean squared error for an `RDD` of (label, prediction) tuples.\n",
      "\n",
      "    Args:\n",
      "        labelsAndPred (RDD of (float, float)): An `RDD` consisting of (label, prediction) tuples.\n",
      "\n",
      "    Returns:\n",
      "        float: The square root of the mean of the squared errors.\n",
      "    \"\"\"\n",
      "    newRDD = labelsAndPreds.map(lambda (x,y) : squaredError(x,y))    \n",
      "    temp = newRDD.map(lambda x: (x,1))\n",
      "    temp = temp.reduce(lambda (x1,y1), (x2,y2): (x1+x2,y1+y2))\n",
      "    temp = temp[0]/temp[1]\n",
      "    return ((temp)**0.5)\n",
      "\n",
      "\n",
      "labelsAndPreds = sc.parallelize([(3., 1.), (1., 2.), (2., 2.)])\n",
      "# RMSE = sqrt[((3-1)^2 + (1-2)^2 + (2-2)^2) / 3] = 1.291\n",
      "exampleRMSE = calcRMSE(labelsAndPreds)\n",
      "print exampleRMSE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Root mean squared error (2b)\n",
      "Test.assertTrue(np.allclose(squaredError(3, 1), 4.), 'incorrect definition of squaredError')\n",
      "Test.assertTrue(np.allclose(exampleRMSE, 1.29099444874), 'incorrect value for exampleRMSE')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(2c) RMSE do baseline para os conjuntos de treino, valida\u00e7\u00e3o e teste **\n",
      "\n",
      "#### Vamos calcular o RMSE para nossa baseline. Primeiro crie uma RDD de (r\u00f3tulo, predi\u00e7\u00e3o) para cada conjunto, e ent\u00e3o chame a fun\u00e7\u00e3o `calcRMSE`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "labelsAndPredsTrain = parsedTrainData.<COMPLETAR>\n",
      "rmseTrainBase = calcRMSE(labelsAndPredsTrain)\n",
      "\n",
      "labelsAndPredsVal = parsedValData.<COMPLETAR>\n",
      "rmseValBase = calcRMSE(labelsAndPredsVal)\n",
      "\n",
      "labelsAndPredsTest = parsedTestData.<COMPLETAR>\n",
      "rmseTestBase = calcRMSE(labelsAndPredsTest)\n",
      "\n",
      "print 'Baseline Train RMSE = {0:.3f}'.format(rmseTrainBase)\n",
      "print 'Baseline Validation RMSE = {0:.3f}'.format(rmseValBase)\n",
      "print 'Baseline Test RMSE = {0:.3f}'.format(rmseTestBase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Training, validation and test RMSE (2c)\n",
      "Test.assertTrue(np.allclose([rmseTrainBase, rmseValBase, rmseTestBase],\n",
      "                            [21.305869, 21.586452, 22.136957]), 'incorrect RMSE value')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** Visualiza\u00e7\u00e3o 2: Predi\u00e7\u00e3o vs. real **\n",
      "\n",
      "#### Vamos visualizar as predi\u00e7\u00f5es no conjunto de valida\u00e7\u00e3o. Os gr\u00e1ficos de dispers\u00e3o abaixo plotam os pontos com a coordenada X sendo o valor predito pelo modelo e a coordenada Y o valor real do r\u00f3tulo.\n",
      "\n",
      "#### O primeiro gr\u00e1fico mostra a situa\u00e7\u00e3o ideal, um modelo que acerta todos os r\u00f3tulos. O segundo gr\u00e1fico mostra o desempenho do modelo baseline. As cores dos pontos representam o erro quadr\u00e1tico daquela predi\u00e7\u00e3o, quanto mais pr\u00f3xima do laranja, maior o erro."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.colors import ListedColormap, Normalize\n",
      "from matplotlib.cm import get_cmap\n",
      "cmap = get_cmap('YlOrRd')\n",
      "norm = Normalize()\n",
      "\n",
      "actual = np.asarray(parsedValData\n",
      "                    .map(lambda lp: lp.label)\n",
      "                    .collect())\n",
      "error = np.asarray(parsedValData\n",
      "                   .map(lambda lp: (lp.label, lp.label))\n",
      "                   .map(lambda (l, p): squaredError(l, p))\n",
      "                   .collect())\n",
      "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
      "\n",
      "fig, ax = preparePlot(np.arange(0, 100, 20), np.arange(0, 100, 20))\n",
      "plt.scatter(actual, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.5)\n",
      "ax.set_xlabel('Predicted'), ax.set_ylabel('Actual')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = np.asarray(parsedValData\n",
      "                         .map(lambda lp: averageTrainYear)\n",
      "                         .collect())\n",
      "error = np.asarray(parsedValData\n",
      "                   .map(lambda lp: (lp.label, averageTrainYear))\n",
      "                   .map(lambda (l, p): squaredError(l, p))\n",
      "                   .collect())\n",
      "norm = Normalize()\n",
      "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
      "\n",
      "fig, ax = preparePlot(np.arange(53.0, 55.0, 0.5), np.arange(0, 100, 20))\n",
      "ax.set_xlim(53, 55)\n",
      "plt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.3)\n",
      "ax.set_xlabel('Predicted'), ax.set_ylabel('Actual')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Parte 3: Treinando e avaliando o modelo de regress\u00e3o linear **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (3a) Gradiente do erro **\n",
      "\n",
      "#### Vamos implementar a regress\u00e3o linear atrav\u00e9s do gradiente descendente.\n",
      "#### Lembrando que para atualizar o peso da regress\u00e3o linear fazemos: $$ \\scriptsize \\mathbf{w}_{i+1} = \\mathbf{w}_i - \\alpha_i \\sum_j (\\mathbf{w}_i^\\top\\mathbf{x}_j  - y_j) \\mathbf{x}_j \\,.$$ onde $ \\scriptsize i $ \u00e9 a itera\u00e7\u00e3o do algoritmo, e $ \\scriptsize j $ \u00e9 o objeto sendo observado no momento.\n",
      "\n",
      "#### Primeiro, implemente uma fun\u00e7\u00e3o que calcula esse gradiente do erro para certo objeto: $ \\scriptsize (\\mathbf{w}^\\top \\mathbf{x} - y) \\mathbf{x} \\, ,$ e teste a fun\u00e7\u00e3o em dois exemplos. Use o m\u00e9todo `DenseVector` [dot](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.DenseVector.dot) para representar a lista de atributos (ele tem funcionalidade parecida com o `np.array()`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.linalg import DenseVector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def gradientSummand(weights, lp):\n",
      "    \"\"\"Calculates the gradient summand for a given weight and `LabeledPoint`.\n",
      "\n",
      "    Note:\n",
      "        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n",
      "        within this function.  For example, they both implement the `dot` method.\n",
      "\n",
      "    Args:\n",
      "        weights (DenseVector): An array of model weights (betas).\n",
      "        lp (LabeledPoint): The `LabeledPoint` for a single observation.\n",
      "\n",
      "    Returns:\n",
      "        DenseVector: An array of values the same length as `weights`.  The gradient summand.\n",
      "    \"\"\"\n",
      "    return <COMPLETAR>\n",
      "\n",
      "exampleW = DenseVector([1, 1, 1])\n",
      "exampleLP = LabeledPoint(2.0, [3, 1, 4])\n",
      "\n",
      "summandOne = gradientSummand(exampleW, exampleLP)\n",
      "print summandOne\n",
      "\n",
      "exampleW = DenseVector([.24, 1.2, -1.4])\n",
      "exampleLP = LabeledPoint(3.0, [-1.4, 4.2, 2.1])\n",
      "summandTwo = gradientSummand(exampleW, exampleLP)\n",
      "print summandTwo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Gradient summand (3a)\n",
      "Test.assertTrue(np.allclose(summandOne, [18., 6., 24.]), 'incorrect value for summandOne')\n",
      "Test.assertTrue(np.allclose(summandTwo, [1.7304,-5.1912,-2.5956]), 'incorrect value for summandTwo')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (3b) Use os pesos para fazer a predi\u00e7\u00e3o **\n",
      "#### Agora, implemente a fun\u00e7\u00e3o  `getLabeledPredictions` que recebe como par\u00e2metro o conjunto de pesos e um `LabeledPoint` e retorna uma tupla (r\u00f3tulo, predi\u00e7\u00e3o). Lembre-se que podemos predizer um r\u00f3tulo calculando o produto interno dos pesos com os atributos."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def getLabeledPrediction(weights, observation):\n",
      "    \"\"\"Calculates predictions and returns a (label, prediction) tuple.\n",
      "\n",
      "    Note:\n",
      "        The labels should remain unchanged as we'll use this information to calculate prediction\n",
      "        error later.\n",
      "\n",
      "    Args:\n",
      "        weights (np.ndarray): An array with one weight for each features in `trainData`.\n",
      "        observation (LabeledPoint): A `LabeledPoint` that contain the correct label and the\n",
      "            features for the data point.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A (label, prediction) tuple.\n",
      "    \"\"\"\n",
      "    return <COMPLETAR>\n",
      "\n",
      "weights = np.array([1.0, 1.5])\n",
      "predictionExample = sc.parallelize([LabeledPoint(2, np.array([1.0, .5])),\n",
      "                                    LabeledPoint(1.5, np.array([.5, .5]))])\n",
      "labelsAndPredsExample = predictionExample.map(lambda lp: getLabeledPrediction(weights, lp))\n",
      "print labelsAndPredsExample.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Use weights to make predictions (3b)\n",
      "Test.assertEquals(labelsAndPredsExample.collect(), [(2.0, 1.75), (1.5, 1.25)],\n",
      "                  'incorrect definition for getLabeledPredictions')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (3c) Gradiente descendente **\n",
      "#### Finalmente, implemente o algoritmo gradiente descendente para regress\u00e3o linear e teste a fun\u00e7\u00e3o em um exemplo."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "def linregGradientDescent(trainData, numIters):\n",
      "    \"\"\"Calculates the weights and error for a linear regression model trained with gradient descent.\n",
      "\n",
      "    Note:\n",
      "        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n",
      "        within this function.  For example, they both implement the `dot` method.\n",
      "\n",
      "    Args:\n",
      "        trainData (RDD of LabeledPoint): The labeled data for use in training the model.\n",
      "        numIters (int): The number of iterations of gradient descent to perform.\n",
      "\n",
      "    Returns:\n",
      "        (np.ndarray, np.ndarray): A tuple of (weights, training errors).  Weights will be the\n",
      "            final weights (one weight per feature) for the model, and training errors will contain\n",
      "            an error (RMSE) for each iteration of the algorithm.\n",
      "    \"\"\"\n",
      "    # The length of the training data\n",
      "    n = trainData.<COMPLETAR>\n",
      "    # The number of features in the training data\n",
      "    d = <COMPLETAR>\n",
      "    w = np.zeros(d)\n",
      "    alpha = 1.0\n",
      "    # We will compute and store the training error after each iteration\n",
      "    errorTrain = np.zeros(numIters)\n",
      "    for i in range(numIters):\n",
      "        # Use getLabeledPrediction from (3b) with trainData to obtain an RDD of (label, prediction)\n",
      "        # tuples.  Note that the weights all equal 0 for the first iteration, so the predictions will\n",
      "        # have large errors to start.\n",
      "        labelsAndPredsTrain = trainData.<COMPLETAR>\n",
      "        errorTrain[i] = <COMPLETAR>\n",
      "\n",
      "        # Calculate the `gradient`.  Make use of the `gradientSummand` function you wrote in (3a).\n",
      "        # Note that `gradient` sould be a `DenseVector` of length `d`.\n",
      "        gradient = trainData.<COMPLETAR>\n",
      "\n",
      "        # Update the weights\n",
      "        alpha_i = alpha / (n * np.sqrt(i+1))\n",
      "        w -= alpha_i*gradient\n",
      "    return w, errorTrain\n",
      "\n",
      "# create a toy dataset with n = 10, d = 3, and then run 5 iterations of gradient descent\n",
      "# note: the resulting model will not be useful; the goal here is to verify that\n",
      "# linregGradientDescent is working properly\n",
      "exampleN = 10\n",
      "exampleD = 3\n",
      "exampleData = (sc\n",
      "               .parallelize(parsedTrainData.take(exampleN))\n",
      "               .map(lambda lp: LabeledPoint(lp.label, lp.features[0:exampleD])))\n",
      "print exampleData.take(2)\n",
      "exampleNumIters = 5\n",
      "exampleWeights, exampleErrorTrain = linregGradientDescent(exampleData, exampleNumIters)\n",
      "print exampleWeights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Gradient descent (3c)\n",
      "expectedOutput = [48.88110449,  36.01144093, 30.25350092]\n",
      "Test.assertTrue(np.allclose(exampleWeights, expectedOutput), 'value of exampleWeights is incorrect')\n",
      "expectedError = [79.72013547, 30.27835699,  9.27842641,  9.20967856,  9.19446483]\n",
      "Test.assertTrue(np.allclose(exampleErrorTrain, expectedError),\n",
      "                'value of exampleErrorTrain is incorrect')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (3d) Treinando o modelo na base de dados **\n",
      "\n",
      "#### Agora iremos treinar o modelo de regress\u00e3o linear na nossa base de dados de treino e calcular o RMSE na base de valida\u00e7\u00e3o. Lembrem-se que n\u00e3o devemos utilizar a base de teste at\u00e9 que o melhor par\u00e2metro do modelo seja escolhido. \n",
      "\n",
      "#### Para essa tarefa vamos utilizar as fun\u00e7\u00f5es linregGradientDescent, getLabeledPrediction e calcRMSE j\u00e1 implementadas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "numIters = 50\n",
      "weightsLR0, errorTrainLR0 = <COMPLETAR>\n",
      "\n",
      "labelsAndPreds = parsedValData.<COMPLETAR>\n",
      "rmseValLR0 = calcRMSE(labelsAndPreds)\n",
      "\n",
      "print 'Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}'.format(rmseValBase,\n",
      "                                                                       rmseValLR0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Train the model (3d)\n",
      "expectedOutput = [22.64535883, 20.064699, -0.05341901, 8.2931319, 5.79155768, -4.51008084,\n",
      "                  15.23075467, 3.8465554, 9.91992022, 5.97465933, 11.36849033, 3.86452361]\n",
      "Test.assertTrue(np.allclose(weightsLR0, expectedOutput), 'incorrect value for weightsLR0')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** Visualiza\u00e7\u00e3o 3: Erro de Treino **\n",
      "#### Vamos verificar o comportamento do algoritmo durante as itera\u00e7\u00f5es. Para isso vamos plotar um gr\u00e1fico em que o eixo x representa a itera\u00e7\u00e3o e o eixo y o log do RMSE. O primeiro gr\u00e1fico mostra as primeiras 50 itera\u00e7\u00f5es enquanto o segundo mostra as \u00faltimas 44 itera\u00e7\u00f5es. Note que inicialmente o erro cai rapidamente, quando ent\u00e3o o gradiente descendente passa a fazer apenas pequenos ajustes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm = Normalize()\n",
      "clrs = cmap(np.asarray(norm(np.log(errorTrainLR0))))[:,0:3]\n",
      "\n",
      "fig, ax = preparePlot(np.arange(0, 60, 10), np.arange(2, 6, 1))\n",
      "ax.set_ylim(2, 6)\n",
      "plt.scatter(range(0, numIters), np.log(errorTrainLR0), s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\n",
      "ax.set_xlabel('Iteration'), ax.set_ylabel(r'$\\log_e(errorTrainLR0)$')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm = Normalize()\n",
      "clrs = cmap(np.asarray(norm(errorTrainLR0[6:])))[:,0:3]\n",
      "\n",
      "fig, ax = preparePlot(np.arange(0, 60, 10), np.arange(17, 22, 1))\n",
      "ax.set_ylim(17.8, 21.2)\n",
      "plt.scatter(range(0, numIters-6), errorTrainLR0[6:], s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\n",
      "ax.set_xticklabels(map(str, range(6, 66, 10)))\n",
      "ax.set_xlabel('Iteration'), ax.set_ylabel(r'Training Error')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Part 4: Treino utilizando MLlib e Busca em Grade (Grid Search) **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(4a) `LinearRegressionWithSGD` **\n",
      "\n",
      "#### Nosso teste inicial j\u00e1 conseguiu obter um desempenho melhor que o baseline, mas vamos ver se conseguimos fazer melhor introduzindo a ordenada de origem da reta al\u00e9m de outros ajustes no algoritmo.  MLlib [LinearRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionWithSGD) implementa o mesmo algoritmo da parte (3b), mas de forma mais eficiente para o contexto distribu\u00eddo e com v\u00e1rias funcionalidades adicionais. \n",
      "\n",
      "#### Primeiro utilize a fun\u00e7\u00e3o LinearRegressionWithSGD para treinar um modelo com regulariza\u00e7\u00e3o L2 (Ridge) e com a ordenada de origem. Esse m\u00e9todo retorna um [LinearRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel).  \n",
      "\n",
      "#### Em seguida, use os atributos [weights](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.weights) e  [intercept](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.intercept) para imprimir o modelo encontrado."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
      "# Values to use when training the linear regression model\n",
      "numIters = 500  # iterations\n",
      "alpha = 1.0  # step\n",
      "miniBatchFrac = 1.0  # miniBatchFraction\n",
      "reg = 1e-1  # regParam\n",
      "regType = 'l2'  # regType\n",
      "useIntercept = True  # intercept"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "firstModel = LinearRegressionWithSGD.train(parsedTrainData, iterations = numIters, step = alpha, miniBatchFraction = 1.0,\n",
      "                                          regParam=reg,regType=regType, intercept=useIntercept)\n",
      "\n",
      "# weightsLR1 stores the model weights; interceptLR1 stores the model intercept\n",
      "weightsLR1 = firstModel.<COMPLETAR>\n",
      "interceptLR1 = firstModel.<COMPLETAR>\n",
      "print weightsLR1, interceptLR1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST LinearRegressionWithSGD (4a)\n",
      "expectedIntercept = 13.3335907631\n",
      "expectedWeights = [16.682292427, 14.7439059559, -0.0935105608897, 6.22080088829, 4.01454261926, -3.30214858535,\n",
      "                   11.0403027232, 2.67190962854, 7.18925791279, 4.46093254586, 8.14950409475, 2.75135810882]\n",
      "Test.assertTrue(np.allclose(interceptLR1, expectedIntercept), 'incorrect value for interceptLR1')\n",
      "Test.assertTrue(np.allclose(weightsLR1, expectedWeights), 'incorrect value for weightsLR1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### **(4b) Predi\u00e7\u00e3o**\n",
      "#### Agora use o m\u00e9todo [LinearRegressionModel.predict()](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.predict) para fazer a predi\u00e7\u00e3o de um objeto. Passe o atributo `features` de um `LabeledPoint` comp par\u00e2metro."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "samplePoint = parsedTrainData.take(1)[0]\n",
      "samplePrediction = firstModel.<COMPLETAR>\n",
      "print samplePrediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Predict (4b)\n",
      "Test.assertTrue(np.allclose(samplePrediction, 56.8013380112),\n",
      "                'incorrect value for samplePrediction')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4c) Avaliar RMSE **\n",
      "\n",
      "#### Agora avalie o desempenho desse modelo no teste de valida\u00e7\u00e3o. Use o m\u00e9todo `predict()` para criar o RDD `labelsAndPreds` RDD, e ent\u00e3o use a fun\u00e7\u00e3o `calcRMSE()` da Parte (2b) para calcular o RMSE."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "labelsAndPreds = parsedValData.<COMPLETAR>\n",
      "rmseValLR1 = calcRMSE(labelsAndPreds)\n",
      "\n",
      "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}' +\n",
      "       '\\n\\tLR1 = {2:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Evaluate RMSE (4c)\n",
      "Test.assertTrue(np.allclose(rmseValLR1, 19.691247), 'incorrect value for rmseValLR1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4d) Grid search **\n",
      "#### J\u00e1 estamos superando o baseline em pelo menos dois anos na m\u00e9dia, vamos ver se encontramos um conjunto de par\u00e2metros melhor.  Fa\u00e7a um grid search para encontrar um bom par\u00e2metro de regulariza\u00e7\u00e3o.  Tente valores para `regParam` dentro do conjunto `1e-10`, `1e-5`, e `1`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "bestRMSE = rmseValLR1\n",
      "bestRegParam = reg\n",
      "bestModel = firstModel\n",
      "\n",
      "numIters = 500\n",
      "alpha = 1.0\n",
      "miniBatchFrac = 1.0\n",
      "for reg in <COMPLETAR>:\n",
      "    model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
      "                                          miniBatchFrac, regParam=reg,\n",
      "                                          regType='l2', intercept=True)\n",
      "    labelsAndPreds = parsedValData.<COMPLETAR>\n",
      "    rmseValGrid = calcRMSE(labelsAndPreds)\n",
      "    print rmseValGrid\n",
      "\n",
      "    if rmseValGrid < bestRMSE:\n",
      "        bestRMSE = rmseValGrid\n",
      "        bestRegParam = reg\n",
      "        bestModel = model\n",
      "rmseValLRGrid = bestRMSE\n",
      "\n",
      "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n' +\n",
      "       '\\tLRGrid = {3:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1, rmseValLRGrid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Grid search (4d)\n",
      "Test.assertTrue(np.allclose(17.017170, rmseValLRGrid), 'incorrect value for rmseValLRGrid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** Visualiza\u00e7\u00e3o 5: Predi\u00e7\u00f5es do melhor modelo**\n",
      "#### Agora, vamos criar um gr\u00e1fico para verificar o desempenho do melhor modelo. Reparem nesse gr\u00e1fico que a quantidade de pontos mais escuros reduziu bastante em rela\u00e7\u00e3o ao baseline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = np.asarray(parsedValData\n",
      "                         .map(lambda lp: bestModel.predict(lp.features))\n",
      "                         .collect())\n",
      "actual = np.asarray(parsedValData\n",
      "                    .map(lambda lp: lp.label)\n",
      "                    .collect())\n",
      "error = np.asarray(parsedValData\n",
      "                   .map(lambda lp: (lp.label, bestModel.predict(lp.features)))\n",
      "                   .map(lambda (l, p): squaredError(l, p))\n",
      "                   .collect())\n",
      "\n",
      "norm = Normalize()\n",
      "clrs = cmap(np.asarray(norm(error)))[:,0:3]\n",
      "\n",
      "fig, ax = preparePlot(np.arange(0, 120, 20), np.arange(0, 120, 20))\n",
      "ax.set_xlim(15, 82), ax.set_ylim(-5, 105)\n",
      "plt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=.5)\n",
      "ax.set_xlabel('Predicted'), ax.set_ylabel(r'Actual')\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (4e) Grid Search para o valor de alfa e n\u00famero de itera\u00e7\u00f5es **\n",
      "\n",
      "####Agora, vamos verificar diferentes valores para alfa e n\u00famero de itera\u00e7\u00f5es para perceber o impacto desses par\u00e2metros em nosso modelo. Especificamente tente os valores  `1e-5` e `10` para `alpha` e os valores `500` e `5` para n\u00famero de itera\u00e7\u00f5es. Avalie todos os modelos no conjunto de valda\u00e7\u00e3o.  Reparem que com um valor baixo de alpha, o algoritmo necessita de muito mais itera\u00e7\u00f5es para convergir ao \u00f3timo, enquanto um valor muito alto para alpha, pode fazer com que o algoritmo n\u00e3o encontre uma solu\u00e7\u00e3o."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "reg = bestRegParam\n",
      "modelRMSEs = []\n",
      "\n",
      "for alpha in <COMPLETAR>:\n",
      "    for numIters in <COMPLETAR>:\n",
      "        model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\n",
      "                                              miniBatchFrac, regParam=reg,\n",
      "                                              regType='l2', intercept=True)\n",
      "        labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\n",
      "        rmseVal = calcRMSE(labelsAndPreds)\n",
      "        print 'alpha = {0:.0e}, numIters = {1}, RMSE = {2:.3f}'.format(alpha, numIters, rmseVal)\n",
      "        modelRMSEs.append(rmseVal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Vary alpha and the number of iterations (4e)\n",
      "expectedResults = sorted([56.969705, 56.892949, 355124752.221221])\n",
      "Test.assertTrue(np.allclose(sorted(modelRMSEs)[:3], expectedResults), 'incorrect value for modelRMSEs')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "** Parte 5: Adicionando atributos n\u00e3o-lineares **"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (5a) Intera\u00e7\u00f5es par a par **\n",
      "\n",
      "#### Conforme mencionado em aula, os modelos de regress\u00e3o linear conseguem capturar as rela\u00e7\u00f5es lineares entre os atributos e o r\u00f3tulo. Por\u00e9m, em muitos casos a rela\u00e7\u00e3o entre eles \u00e9 n\u00e3o-linear.\n",
      "\n",
      "#### Uma forma de resolver tal problema \u00e9 criando mais atributos com caracter\u00edsticas n\u00e3o-lineares, como por exemplo a expans\u00e3o quadr\u00e1tica dos atributos originais. Escreva uma fun\u00e7\u00e3o `twoWayInteractions` que recebe um  `LabeledPoint` e gera um novo `LabeledPoint` que cont\u00e9m os atributos antigos e as intera\u00e7\u00f5es par a par entre eles. Note que um objeto com 3 atributos ter\u00e1 nove intera\u00e7\u00f5es ( $ \\scriptsize 3^2 $ ) par a par.\n",
      "\n",
      "#### Para facilitar, utilize o m\u00e9todo [itertools.product](https://docs.python.org/2/library/itertools.html#itertools.product) para gerar tuplas para cada poss\u00edvel intera\u00e7\u00e3o. Utilize tamb\u00e9m [np.hstack](http://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html#numpy.hstack) para concatenar dois vetores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "import itertools\n",
      "\n",
      "def twoWayInteractions(lp):\n",
      "    \"\"\"Creates a new `LabeledPoint` that includes two-way interactions.\n",
      "\n",
      "    Note:\n",
      "        For features [x, y] the two-way interactions would be [x^2, x*y, y*x, y^2] and these\n",
      "        would be appended to the original [x, y] feature list.\n",
      "\n",
      "    Args:\n",
      "        lp (LabeledPoint): The label and features for this observation.\n",
      "\n",
      "    Returns:\n",
      "        LabeledPoint: The new `LabeledPoint` should have the same label as `lp`.  Its features\n",
      "            should include the features from `lp` followed by the two-way interaction features.\n",
      "    \"\"\"\n",
      "    newfeats = <COMPLETAR>\n",
      "    return LabeledPoint(lp.label, <COMPLETAR>)\n",
      "    #return lp\n",
      "    \n",
      "\n",
      "print twoWayInteractions(LabeledPoint(0.0, [2, 3]))\n",
      "\n",
      "# Transform the existing train, validation, and test sets to include two-way interactions.\n",
      "trainDataInteract = parsedTrainData.map(twoWayInteractions)\n",
      "valDataInteract = parsedValData.map(twoWayInteractions)\n",
      "testDataInteract = parsedTestData.map(twoWayInteractions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Add two-way interactions (5a)\n",
      "twoWayExample = twoWayInteractions(LabeledPoint(0.0, [2, 3]))\n",
      "Test.assertTrue(np.allclose(sorted(twoWayExample.features),\n",
      "                            sorted([2.0, 3.0, 4.0, 6.0, 6.0, 9.0])),\n",
      "                'incorrect features generatedBy twoWayInteractions')\n",
      "twoWayPoint = twoWayInteractions(LabeledPoint(1.0, [1, 2, 3]))\n",
      "Test.assertTrue(np.allclose(sorted(twoWayPoint.features),\n",
      "                            sorted([1.0,2.0,3.0,1.0,2.0,3.0,2.0,4.0,6.0,3.0,6.0,9.0])),\n",
      "                'incorrect features generated by twoWayInteractions')\n",
      "Test.assertEquals(twoWayPoint.label, 1.0, 'incorrect label generated by twoWayInteractions')\n",
      "Test.assertTrue(np.allclose(sum(trainDataInteract.take(1)[0].features), 40.821870576035529),\n",
      "                'incorrect features in trainDataInteract')\n",
      "Test.assertTrue(np.allclose(sum(valDataInteract.take(1)[0].features), 45.457719932695696),\n",
      "                'incorrect features in valDataInteract')\n",
      "Test.assertTrue(np.allclose(sum(testDataInteract.take(1)[0].features), 35.109111632783168),\n",
      "                'incorrect features in testDataInteract')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (5b) Construindo um novo modelo **\n",
      "\n",
      "#### Agora construa um novo modelo usando esses novos atributos. Repare que idealmente, com novos atributos, voc\u00ea deve realizar um novo Grid Search para determinar os novos par\u00e2metros \u00f3timos, uma vez que os par\u00e2metros do modelo anterior n\u00e3o necessariamente funcionar\u00e3o aqui.\n",
      "\n",
      "#### Para este exerc\u00edcio, os par\u00e2metros j\u00e1 foram otimizados."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "numIters = 500\n",
      "alpha = 1.0\n",
      "miniBatchFrac = 1.0\n",
      "reg = 1e-10\n",
      "\n",
      "modelInteract = LinearRegressionWithSGD.train(trainDataInteract, numIters, alpha,\n",
      "                                              miniBatchFrac, regParam=reg,\n",
      "                                              regType='l2', intercept=True)\n",
      "labelsAndPredsInteract = valDataInteract.<COMPLETAR>\n",
      "rmseValInteract = calcRMSE(labelsAndPredsInteract)\n",
      "\n",
      "print ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n\\tLRGrid = ' +\n",
      "       '{3:.3f}\\n\\tLRInteract = {4:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1,\n",
      "                                                 rmseValLRGrid, rmseValInteract)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Build interaction model (5b)\n",
      "Test.assertTrue(np.allclose(rmseValInteract, 15.6894664683), 'incorrect value for rmseValInteract')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ** (5c) Avaliando o modelo de intera\u00e7\u00e3o **\n",
      "\n",
      "#### Finalmente, temos que o melhor modelo para o conjunto de valida\u00e7\u00e3o foi o modelo de intera\u00e7\u00e3o. Na pr\u00e1tica esse seria o modelo escolhido para aplicar nos modelos n\u00e3o-rotulados. Vamos ver como essa escolha se sairia utilizand a base de teste nesse modelo e no baseline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# EXERCICIO\n",
      "labelsAndPredsTest = testDataInteract.<COMPLETAR>\n",
      "rmseTestInteract = calcRMSE(labelsAndPredsTest)\n",
      "\n",
      "print ('Test RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLRInteract = {1:.3f}'\n",
      "       .format(rmseTestBase, rmseTestInteract))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TEST Evaluate interaction model on test data (5c)\n",
      "Test.assertTrue(np.allclose(rmseTestInteract, 16.3272040537),\n",
      "                'incorrect value for rmseTestInteract')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}